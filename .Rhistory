anova(m5)
odds.ratio(m5)
library(surveyr)
library(questionr)
odds.ratio(m5)
library(readr)
library(tidytext)
library(dplyr)
library(tidyr)
library(stringr)
library(Amelia)
library(tidyr)
library(logistf)
library(pscl)
library(ROCR)
library(MKmisc)
library(survey)
library(ResourceSelection)
library(caret)
library(lattice)
library(surveyr)
install.packages("surveyr")
library(surveyr)
library(surveyr)
library(questionr)
ldata <- read_csv("C:/Users/choco/Desktop/SPRING 2018/Capstone/FINAL_DATA_FOR_MODELS.csv")
ldata<-ldata %>%
select(-URL, -Title,-Impact,-Engaged_minutes,-Returning_vis.,-Search_refs,-Internal_refs,-Other_refs,-Direct_refs,-Fb_refs,-Tw_refs,-Fb_interactions,-total_words)
ldata[is.na(ldata)]<-0
set.seed(1)
smp_size <- floor(0.75 * nrow(ldata))
train_ind <- sample(seq_len(nrow(ldata)), size = smp_size)
train <- ldata[train_ind, ]
test <- ldata[-train_ind, ]
m1 <- glm(impact~.,family=binomial(link = "logit"), data=train)
step(m1,direction="both")
m5<-glm(formula = impact ~ Avg._views_ret._vis. + Mobile_views +
smog_index + neg1 + neg2 + neg3 + neg5 + pos1 + pos2 + pos4 +
Li_ref + Engaged_hours + Other_refs_10000 + Fb_interactions_10000 +
total_words_10, family = binomial(link = "logit"), data = train)
summary(m5)
m5<-glm(formula = impact ~ Avg._views_ret._vis. + Mobile_views/1000 +
smog_index + neg1 + neg2 + neg3 + neg5 + pos1 + pos2 + pos4 +
Li_ref + Engaged_hours + Other_refs_10000 + Fb_interactions_10000 +
total_words_10, family = binomial(link = "logit"), data = train)
str(ldata$Mobile_views)
Mobile_views/1000
ldata$Mobile_views/1000
m5<-glm(formula = impact ~ Avg._views_ret._vis. + (Mobile_views/1000) +
smog_index + neg1 + neg2 + neg3 + neg5 + pos1 + pos2 + pos4 +
Li_ref + Engaged_hours + Other_refs_10000 + Fb_interactions_10000 +
total_words_10, family = binomial(link = "logit"), data = train)
m5<-glm(formula = impact ~ Avg._views_ret._vis. + (as.integer(Mobile_views)/1000) +
smog_index + neg1 + neg2 + neg3 + neg5 + pos1 + pos2 + pos4 +
Li_ref + Engaged_hours + Other_refs_10000 + Fb_interactions_10000 +
total_words_10, family = binomial(link = "logit"), data = train)
m5<-glm(formula = impact ~ Avg._views_ret._vis. + Mobile_views +
smog_index + neg1 + neg2 + neg3 + neg5 + pos1 + pos2 + pos4 +
Li_ref + Engaged_hours + Other_refs_10000 + Fb_interactions_10000 +
total_words_10, family = binomial(link = "logit"), data = train)
summary(m5)
anova(m5)
odds.ratio(m5)
m5<-glm(formula = impact ~ Avg._views_ret._vis. + Mobile_views +
smog_index + neg1 + neg2 + neg3 + neg5 + pos1 + pos2 + pos4 +
Li_ref + Engaged_hours + Other_refs_10000 + Fb_interactions_10000 +
total_words_10, family = binomial(link = "logit"), data = train)
m5<-glm(formula = impact ~ Avg._views_ret._vis. + Mobile_views/1000 +
smog_index + neg1 + neg2 + neg3 + neg5 + pos1 + pos2 + pos4 +
Li_ref + Engaged_hours + Other_refs_10000 + Fb_interactions_10000 +
total_words_10, family = binomial(link = "logit"), data = train)
m5<-glm(formula = impact ~ Avg._views_ret._vis. + Mobile_views +
smog_index + neg1 + neg2 + neg3 + neg5 + pos1 + pos2 + pos4 +
Li_ref + Engaged_hours + Other_refs_10000 + Fb_interactions_10000 +
total_words_10, family = binomial(link = "logit"), data = train)
save(m5,file="C:/Users/choco/Desktop/SPRING 2018/Capstone/logistic_regression_05062018.rda")
summary(m5)
anova(m5)
odds.ratio(m5)
xyplot(log(fitted.values(m5)/(1-fitted.values(m5)))~impact, data=ldata, type=c("l"),ylab="log odds")
xyplot(fitted.values(m5)/(1-fitted.values(m5))~impact, data=ldata, ylab="odds")
prob <- predict(m5, newdata=test, type="response")
pred <- prediction(prob, test$impact)
perf <- performance(pred, measure = "tpr", x.measure = "fpr")
plot(perf)
auc <- performance(pred, measure = "auc")
auc <- auc@y.values[[1]]
auc
xyplot(log(fitted.values(m5)/(1-fitted.values(m5)))~impact, data=ldata, type=c("l"),ylab="log odds")
xyplot(fitted.values(m5)/(1-fitted.values(m5))~impact, data=ldata, ylab="odds")
test$impact<-as.factor(test$impact)
ldata$impact <- as.factor(ldata$impact)
ctrl <- trainControl(method = "repeatedcv", number = 10, savePredictions = TRUE)
mod_fit <- train(impact ~ Engaged_minutes + Returning_vis. + Avg._views_ret._vis. +
Avg._minutes_ret._vis. + Desktop_views + Mobile_views + Search_refs +
Internal_refs + Other_refs + Direct_refs + Fb_refs + Tw_refs +
Fb_interactions + smog_index + total_words + neg1 + neg2 +
neg3 + neg5 + pos1 + pos2 + pos4 + Li_ref,  data=ldata, method="glm", family="binomial", trControl = ctrl, tuneLength = 5)
mod_fit <- train(m5, method="glm", family="binomial", trControl = ctrl, tuneLength = 5)
mod_fit <- train(impact ~ Avg._views_ret._vis. + Mobile_views +
smog_index + neg1 + neg2 + neg3 + neg5 + pos1 + pos2 + pos4 +
Li_ref + Engaged_hours + Other_refs_10000 + Fb_interactions_10000 +
total_words_10, method="glm", family="binomial", trControl = ctrl, tuneLength = 5)
mod_fit <- train(impact ~ Avg._views_ret._vis. + Mobile_views +
smog_index + neg1 + neg2 + neg3 + neg5 + pos1 + pos2 + pos4 +
Li_ref + Engaged_hours + Other_refs_10000 + Fb_interactions_10000 +
total_words_10, data=ldata, method="glm", family="binomial", trControl = ctrl, tuneLength = 5)
pred <- predict(mod_fit, newdata=test)
cfm1<-confusionMatrix(data=pred, test$impact,positive = "1")
cfm1
m6 <- load(file = "C:/Users/choco/Desktop/SPRING 2018/Capstone/logistic_regression_model_s4.rda")
m6
summary(m6)
load(file = "C:/Users/choco/Desktop/SPRING 2018/Capstone/logistic_regression_model_s4.rda")
library(dplyr)
library(mosaic)
library(randomForest)
library(ParetoPosStable)
library(tree)
library(caret)
library(gbm)
library(adabag)
library(EnvStats)
library(Hmisc)
library(tidyr)
set.seed(5)
fitControl = trainControl(method="cv", summaryFunction =  twoClassSummary, classProbs = TRUE, number = 5, returnResamp = "all")
m6 <- train(Impact~., data=clean_boost2, method="gbm", trControl=fitControl, tuneGrid=data.frame(.n.trees=best.iter, .shrinkage=0.01, .interaction.depth=1, .n.minobsinnode=1), verbose=FALSE,  metric = "ROC", distribution = "bernoulli")
clean_boost2 <- clean_boost %>%
mutate(Impact = ifelse(Impact1 == 1, "Y", "N" )) %>%
select(-Impact1)
clean_boost <- clean_200 %>%
select( -Tags, -`Sort_(Views)`, -text, -keywords, -summary, -URL, -Title, -Authors, -Section, -Publish_date, -X1)
rated_200 <- rated_200 %>%
mutate(Impact1 = ifelse(Impact == 9, 1, ifelse(Impact == 1, 1, 0)))%>%
select(-Impact)
rated_200 <- rated_200 %>%
mutate(Impact1 = ifelse(Impact == 9, 1, ifelse(Impact == 1, 1, 0)))%>%
select(-Impact)
spaceless <- function(x) {colnames(x) <- gsub(" ", "_", colnames(x));x}
hless <- function(x) {colnames(x) <- gsub("-", "_", colnames(x));x}
clean_200 <- spaceless(rated_200)
rated_200<-ldata
##Boosting with Classification
clean_boost <- clean_200 %>%
select( -Tags, -`Sort_(Views)`, -text, -keywords, -summary, -URL, -Title, -Authors, -Section, -Publish_date, -X1)
m5<- gbm(Impact1 ~., data = clean_boost, distribution = "bernoulli", n.trees = 500, cv.folds = 5, verbose = F)
best.iter = gbm.perf(m5, method = "cv")
clean_boost2 <- clean_boost %>%
mutate(Impact = ifelse(Impact1 == 1, "Y", "N" )) %>%
select(-Impact1)
set.seed(5)
fitControl = trainControl(method="cv", summaryFunction =  twoClassSummary, classProbs = TRUE, number = 5, returnResamp = "all")
m6 <- train(Impact~., data=clean_boost2, method="gbm", trControl=fitControl, tuneGrid=data.frame(.n.trees=best.iter, .shrinkage=0.01, .interaction.depth=1, .n.minobsinnode=1), verbose=FALSE,  metric = "ROC", distribution = "bernoulli")
m6
confusionMatrix(m6)
m6_estimates = predict(m6, clean_boost2)
postResample(m6_estimates, as.factor(clean_boost2$Impact))
library(readr)
library(tidytext)
library(dplyr)
library(tidyr)
library(stringr)
library(Amelia)
library(tidyr)
library(logistf)
library(pscl)
library(ROCR)
library(MKmisc)
library(survey)
library(ResourceSelection)
library(caret)
library(lattice)
library(questionr)
ldata <- read_csv("C:/Users/choco/Desktop/SPRING 2018/Capstone/FINAL_DATA_FOR_MODELS.csv")
ldata<-ldata %>%
select(-URL, -Title,-Impact,-Engaged_minutes,-Returning_vis.,-Search_refs,-Internal_refs,-Other_refs,-Direct_refs,-Fb_refs,-Tw_refs,-Fb_interactions,-total_words)
ldata[is.na(ldata)]<-0
#split into train and test
set.seed(1)
smp_size <- floor(0.75 * nrow(ldata))
train_ind <- sample(seq_len(nrow(ldata)), size = smp_size)
train <- ldata[train_ind, ]
test <- ldata[-train_ind, ]
m1 <- glm(impact~.,family=binomial(link = "logit"), data=train)
step(m1,direction="both")
# m5<-glm(formula = impact ~ Views + Engaged_minutes + New_vis. + Avg._views_new_vis. +
#     Avg._minutes_new_vis. + Desktop_views + Internal_refs + Fb_interactions +
#     smog_index + total_words + neg1 + neg2 + neg3 + neg4 + neg5 +
#     pos1 + pos2 + pos3 + pos4, family = binomial(link = "logit"),
#     data = train)
# m5<-glm(formula = impact ~ Engaged_minutes + Returning_vis. + Avg._views_ret._vis. +
#     Avg._minutes_ret._vis. + Desktop_views + Mobile_views + Search_refs +
#     Internal_refs + Other_refs + Direct_refs + Fb_refs + Tw_refs +
#     Fb_interactions + smog_index + total_words + neg1 + neg2 +
#     neg3 + neg5 + pos1 + pos2 + pos4 + Li_ref, family = binomial(link = "logit"),
#     data = train)
# m5<-glm(formula = impact ~ Avg._views_ret._vis. + Avg._minutes_ret._vis. +
#     Desktop_views + Mobile_views + smog_index + neg1 + neg2 +
#     neg3 + neg5 + pos1 + pos2 + pos4 + Li_ref + Engaged_hours +
#     Returning_vis_10000 + Search_refs_10000 + Internal_refs_10000 +
#     Other_refs_10000 + Direct_refs_10000 + Fb_refs_10000 + Tw_refs_10000 +
#     Fb_interactions_10000 + total_words_10, family = binomial(link = "logit"),
#     data = train)
m5<-glm(formula = impact ~ Avg._views_ret._vis. + Mobile_views +
smog_index + neg1 + neg2 + neg3 + neg5 + pos1 + pos2 + pos4 +
Li_ref + Engaged_hours + Other_refs_10000 + Fb_interactions_10000 +
total_words_10, family = binomial(link = "logit"), data = train)
save(m5,file="C:/Users/choco/Desktop/SPRING 2018/Capstone/logistic_regression_05062018.rda")
summary(m5)
anova(m5)
odds.ratio(m5)
pR2(m5)
xyplot(log(fitted.values(m5)/(1-fitted.values(m5)))~impact, data=ldata, type=c("l"),ylab="log odds")
xyplot(fitted.values(m5)/(1-fitted.values(m5))~impact, data=ldata, ylab="odds")
# fitted.results <- predict(m5,newdata=subset(train,select=c(2,3,4,5,6,7,8)),type='response')
# fitted.results <- ifelse(fitted.results > 0.5,1,0)
# misClasificError <- mean(fitted.results != ldata2$impact)
# print(paste('Accuracy',1-misClasificError))
# p <- predict(m5, newdata=subset(test,select=c(2,3,4,5,6,7,8)), type="response")
# pr <- prediction(p, ldata$impact)
# prf <- performance(pr, measure = "tpr", x.measure = "fpr")
# plot(prf)
#
# auc <- performance(pr, measure = "auc")
# auc <- auc@y.values[[1]]
# auc
# Compute AUC for predicting Class with the model
prob <- predict(m5, newdata=test, type="response")
pred <- prediction(prob, test$impact)
perf <- performance(pred, measure = "tpr", x.measure = "fpr")
plot(perf)
auc <- performance(pred, measure = "auc")
auc <- auc@y.values[[1]]
auc
test$impact<-as.factor(test$impact)
ldata$impact <- as.factor(ldata$impact)
ctrl <- trainControl(method = "repeatedcv", number = 10, savePredictions = TRUE)
mod_fit <- train(impact ~ Avg._views_ret._vis. + Mobile_views +
smog_index + neg1 + neg2 + neg3 + neg5 + pos1 + pos2 + pos4 +
Li_ref + Engaged_hours + Other_refs_10000 + Fb_interactions_10000 +
total_words_10, data=ldata, method="glm", family="binomial", trControl = ctrl, tuneLength = 5)
pred <- predict(mod_fit, newdata=test)
cfm1<-confusionMatrix(data=pred, test$impact,positive = "1")
cfm1
save(m5, file = "C:/Users/choco/Desktop/SPRING 2018/Capstone/logistic_regression_model_s4.rda")
auc
library(ROCR)
plot(perf)
plot(perf)
auc <- performance(pred, measure = "auc")
auc <- auc@y.values[[1]]
auc
plot(perf,colorize=TRUE)
gbmtest<-read_csv("C:/Users/choco/Desktop/SPRING 2018/Capstone/gbm_predictions.csv")
plot(gbmtest,add=TRUE)
pf<-read_csv("C:/Users/choco/Desktop/SPRING 2018/Capstone/gbm_predictions.csv")
pf2 <- pf %>%
mutate(Impact2 = as.factor(Impact))
predictions2<-read_csv("C:/Users/choco/Desktop/SPRING 2018/Capstone/gbm_predictions.csv")
gbm.ROC <- roc(predictor=predictions2$Y,
response=pf2$Impact2,
levels=rev(levels(pf2$Impact2)))
View(pf)
gbm.ROC <- roc(predictor=predictions2$Y,
response=pf2$Impact2,
levels=rev(levels(pf2$Impact2)))
prob <- predict(m5_1, newdata=test, type="response")
prob <- predict(m5, newdata=test, type="response")
pred <- prediction(prob, test$impact)
perf <- performance(pred, measure = "tpr", x.measure = "fpr")
plot(perf)
auc <- performance(pred, measure = "auc")
auc <- auc@y.values[[1]]
auc
write.csv(pred,"C:/Users/choco/Desktop/SPRING 2018/Capstone/pred_logistic_regression.csv")
pred
write.csv(as.dataframe(pred),"C:/Users/choco/Desktop/SPRING 2018/Capstone/pred_logistic_regression.csv")
write.csv(as.data.frame(pred),"C:/Users/choco/Desktop/SPRING 2018/Capstone/pred_logistic_regression.csv")
names(pred)
write.csv(data.frame(fp=pred@fp, fn=pred@fn),"C:/Users/choco/Desktop/SPRING 2018/Capstone/pred_logistic_regression.csv")
View(predictions2)
write.csv(data.frame(fp=pred@predictions, fn=pred@labels),"C:/Users/choco/Desktop/SPRING 2018/Capstone/pred_logistic_regression2.csv")
write.csv(data.frame(fp=pred@labels, fn=pred@predictions),"C:/Users/choco/Desktop/SPRING 2018/Capstone/pred_logistic_regression2.csv")
write.csv(data.frame(fp=pred@labels, fn=pred@predictions),"C:/Users/choco/Desktop/SPRING 2018/Capstone/pred_logistic_regression3.csv")
auc <- performance(pred, measure = "auc")
write.csv(data.frame(perf),"C:/Users/choco/Desktop/SPRING 2018/Capstone/pred_logistic_regression3.csv")
pred <- prediction(prob, test$impact)
perf <- performance(pred, measure = "tpr", x.measure = "fpr")
plot(perf)
write.csv(data.frame(fp=perf@x.values, fn=perf@y.values),"C:/Users/choco/Desktop/SPRING 2018/Capstone/pred_logistic_regression3.csv")
write.csv(data.frame(fp=perf@x.values, fn=perf@y.values),"C:/Users/choco/Desktop/SPRING 2018/Capstone/pred_logistic_regression4.csv")
library(pROC)
predictions2 <- predict(object=m5,pred, , type='prob')
head(predictions2)
write.csv(head(predictions2),"C:/Users/choco/Desktop/SPRING 2018/Capstone/pred_logistic_regression3.csv")
write.csv(head(predictions2),"C:/Users/choco/Desktop/SPRING 2018/Capstone/pred_logistic_regression4.csv")
predictions <- predict(m5, pf)
predictions <- predict(m5, pred)
library(pROC)
predictions2 <- predict(object=m5,pred, , type='prob')
write.csv(predictions2,"C:/Users/choco/Desktop/SPRING 2018/Capstone/pred_logistic_regression5.csv")
library(readr)
library(tidytext)
library(dplyr)
library(tidyr)
library(stringr)
library(Amelia)
library(tidyr)
library(logistf)
library(pscl)
library(ROCR)
library(MKmisc)
library(survey)
library(ResourceSelection)
library(caret)
library(lattice)
library(questionr)
ldata <- read_csv("C:/Users/choco/Desktop/SPRING 2018/Capstone/FINAL_DATA_FOR_MODELS.csv")
ldata<-ldata %>%
select(-URL, -Title,-Impact,-Engaged_minutes,-Returning_vis.,-Search_refs,-Internal_refs,-Other_refs,-Direct_refs,-Fb_refs,-Tw_refs,-Fb_interactions,-total_words)
ldata[is.na(ldata)]<-0
#split into train and test
set.seed(1)
smp_size <- floor(0.75 * nrow(ldata))
train_ind <- sample(seq_len(nrow(ldata)), size = smp_size)
train <- ldata[train_ind, ]
test <- ldata[-train_ind, ]
m1 <- glm(impact~.,family=binomial(link = "logit"), data=train)
step(m1,direction="both")
# m5<-glm(formula = impact ~ Views + Engaged_minutes + New_vis. + Avg._views_new_vis. +
#     Avg._minutes_new_vis. + Desktop_views + Internal_refs + Fb_interactions +
#     smog_index + total_words + neg1 + neg2 + neg3 + neg4 + neg5 +
#     pos1 + pos2 + pos3 + pos4, family = binomial(link = "logit"),
#     data = train)
# m5<-glm(formula = impact ~ Engaged_minutes + Returning_vis. + Avg._views_ret._vis. +
#     Avg._minutes_ret._vis. + Desktop_views + Mobile_views + Search_refs +
#     Internal_refs + Other_refs + Direct_refs + Fb_refs + Tw_refs +
#     Fb_interactions + smog_index + total_words + neg1 + neg2 +
#     neg3 + neg5 + pos1 + pos2 + pos4 + Li_ref, family = binomial(link = "logit"),
#     data = train)
# m5<-glm(formula = impact ~ Avg._views_ret._vis. + Avg._minutes_ret._vis. +
#     Desktop_views + Mobile_views + smog_index + neg1 + neg2 +
#     neg3 + neg5 + pos1 + pos2 + pos4 + Li_ref + Engaged_hours +
#     Returning_vis_10000 + Search_refs_10000 + Internal_refs_10000 +
#     Other_refs_10000 + Direct_refs_10000 + Fb_refs_10000 + Tw_refs_10000 +
#     Fb_interactions_10000 + total_words_10, family = binomial(link = "logit"),
#     data = train)
m5<-glm(formula = impact ~ Avg._views_ret._vis. + Mobile_views +
smog_index + neg1 + neg2 + neg3 + neg5 + pos1 + pos2 + pos4 +
Li_ref + Engaged_hours + Other_refs_10000 + Fb_interactions_10000 +
total_words_10, family = binomial(link = "logit"), data = train)
save(m5,file="C:/Users/choco/Desktop/SPRING 2018/Capstone/logistic_regression_05062018.rda")
summary(m5)
anova(m5)
odds.ratio(m5)
pR2(m5)
xyplot(log(fitted.values(m5)/(1-fitted.values(m5)))~impact, data=ldata, type=c("l"),ylab="log odds")
xyplot(fitted.values(m5)/(1-fitted.values(m5))~impact, data=ldata, ylab="odds")
# fitted.results <- predict(m5,newdata=subset(train,select=c(2,3,4,5,6,7,8)),type='response')
# fitted.results <- ifelse(fitted.results > 0.5,1,0)
# misClasificError <- mean(fitted.results != ldata2$impact)
# print(paste('Accuracy',1-misClasificError))
# p <- predict(m5, newdata=subset(test,select=c(2,3,4,5,6,7,8)), type="response")
# pr <- prediction(p, ldata$impact)
# prf <- performance(pr, measure = "tpr", x.measure = "fpr")
# plot(prf)
#
# auc <- performance(pr, measure = "auc")
# auc <- auc@y.values[[1]]
# auc
# Compute AUC for predicting Class with the model
prob <- predict(m5, newdata=test, type="response")
pred <- prediction(prob, test$impact)
perf <- performance(pred, measure = "tpr", x.measure = "fpr")
plot(perf)
auc <- performance(pred, measure = "auc")
auc <- auc@y.values[[1]]
auc
test$impact<-as.factor(test$impact)
ldata$impact <- as.factor(ldata$impact)
ctrl <- trainControl(method = "repeatedcv", number = 10, savePredictions = TRUE)
mod_fit <- train(impact ~ Avg._views_ret._vis. + Mobile_views +
smog_index + neg1 + neg2 + neg3 + neg5 + pos1 + pos2 + pos4 +
Li_ref + Engaged_hours + Other_refs_10000 + Fb_interactions_10000 +
total_words_10, data=ldata, method="glm", family="binomial", trControl = ctrl, tuneLength = 5)
pred <- predict(mod_fit, newdata=test)
cfm1<-confusionMatrix(data=pred, test$impact,positive = "1")
cfm1
save(m5, file = "C:/Users/choco/Desktop/SPRING 2018/Capstone/logistic_regression_model_s4.rda")
predictions2 <- predict(object=m5, pred, type='prob')
predictions2 <- predict(object=m5, perf, type='prob')
library(pROC)
predictions2 <- predict(object=m5, perf, type='prob')
predictions2 <- predict(object=m5, pred, type='prob')
head(predictions2)
predictions <- predict(m5, pred)
predictions2 <- predict(=m5, pred, type='prob')
predictions2 <- predict(m5, pred, type='prob')
predictions2 <- predict(object=m5, pred)
predictions2 <- predict(object=m5, pred, type='prob')
predictions2 <- predict(m5, pred)
predictions2 <- predict(object=m5, pred, type='prob')
?predict
predictions2 <- predict(object=m5, pred, type='response')
m5
predictions2 <- predict(object=m5, ldata)
predictions2 <- predict(object=m5, ldata,type='prob')
head(predictions2)
write.csv(predictions2,"C:/Users/choco/Desktop/SPRING 2018/Capstone/test2222.csv")
predictions2 <- predict(object=m5, pred)
predictions2 <- predict(object=m5, perf)
predictions2 <- predict(object=m5, pred)
library(readr)
library(tidytext)
library(dplyr)
library(tidyr)
library(stringr)
library(Amelia)
library(tidyr)
library(logistf)
library(pscl)
library(ROCR)
library(MKmisc)
library(survey)
library(ResourceSelection)
library(caret)
library(lattice)
library(questionr)
ldata <- read_csv("C:/Users/choco/Desktop/SPRING 2018/Capstone/FINAL_DATA_FOR_MODELS.csv")
ldata<-ldata %>%
select(-URL, -Title,-Impact,-Engaged_minutes,-Returning_vis.,-Search_refs,-Internal_refs,-Other_refs,-Direct_refs,-Fb_refs,-Tw_refs,-Fb_interactions,-total_words)
ldata[is.na(ldata)]<-0
set.seed(1)
smp_size <- floor(0.75 * nrow(ldata))
train_ind <- sample(seq_len(nrow(ldata)), size = smp_size)
train <- ldata[train_ind, ]
test <- ldata[-train_ind, ]
m1 <- glm(log(impact)~.,family=binomial(link = "logit"), data=train)
m1 <- glm(impact~.,family=binomial(link = "logit"), data=train)
View(ldata)
step(m1,direction="both")
a<-c("Model", "SVM", "GBM", "Logistic Regression")
b<- c("Predictor#1 ", "Total words", "Total words", "Average views for returning visitors")
c<- c("Predictor#2", "Average views for returning visitors", "Views", "Mobile Views")
d<-c("Predictor#3", "Smog index", "Other interactions", "Smog Index"), c("Predictor#4", "Internal references", "Tw interactions", "Negative 1")
a<-c("Model", "SVM", "GBM", "Logistic Regression")
b<- c("Predictor#1 ", "Total words", "Total words", "Average views for returning visitors")
c<- c("Predictor#2", "Average views for returning visitors", "Views", "Mobile Views")
a<-c("Model", "SVM", "GBM", "Logistic Regression")
b<- c("Predictor#1 ", "Total words", "Total words", "Average views for returning visitors")
c<- c("Predictor#2", "Average views for returning visitors", "Views", "Mobile Views")
d<-c("Predictor#3", "Smog index", "Other interactions", "Smog Index")
e<-c("Predictor#4", "Internal references", "Tw interactions", "Negative 1")
f<-c("Predictor#5", "Positive 4", "Fb interactions", "Negative 2")
g<-c("Predictor#6", "Engaged mins", "Visitors", "Negative 3")
data.frame(c(a,b,c,d,e,f,g))
data.frame(c(a,b,c,d,e,f,g))
ldata<-ldata%>%
mutate(Mobile_views_10000=Mobile_views/10000)
library(dplyr)
library(readr)
library(tidytext)
library(dplyr)
library(tidyr)
library(stringr)
library(Amelia)
library(tidyr)
library(logistf)
library(pscl)
library(ROCR)
library(MKmisc)
library(survey)
library(ResourceSelection)
library(caret)
library(lattice)
library(questionr)
ldata <- read_csv("C:/Users/choco/Desktop/SPRING 2018/Capstone/FINAL_DATA_FOR_MODELS.csv")
ldata<-ldata %>%
mutate(Mobile_views_10000=Mobile_views/10000)%>%
select(-Mobile_views,-URL, -Title,-Impact,-Engaged_minutes,-Returning_vis.,-Search_refs,-Internal_refs,-Other_refs,-Direct_refs,-Fb_refs,-Tw_refs,-Fb_interactions,-total_words)
ldata[is.na(ldata)]<-0
#split into train and test
set.seed(1)
smp_size <- floor(0.75 * nrow(ldata))
train_ind <- sample(seq_len(nrow(ldata)), size = smp_size)
train <- ldata[train_ind, ]
test <- ldata[-train_ind, ]
m1 <- glm(impact~.,family=binomial(link = "logit"), data=train)
step(m1,direction="both")
# m5<-glm(formula = impact ~ Views + Engaged_minutes + New_vis. + Avg._views_new_vis. +
#     Avg._minutes_new_vis. + Desktop_views + Internal_refs + Fb_interactions +
#     smog_index + total_words + neg1 + neg2 + neg3 + neg4 + neg5 +
#     pos1 + pos2 + pos3 + pos4, family = binomial(link = "logit"),
#     data = train)
# m5<-glm(formula = impact ~ Engaged_minutes + Returning_vis. + Avg._views_ret._vis. +
#     Avg._minutes_ret._vis. + Desktop_views + Mobile_views + Search_refs +
#     Internal_refs + Other_refs + Direct_refs + Fb_refs + Tw_refs +
#     Fb_interactions + smog_index + total_words + neg1 + neg2 +
#     neg3 + neg5 + pos1 + pos2 + pos4 + Li_ref, family = binomial(link = "logit"),
#     data = train)
# m5<-glm(formula = impact ~ Avg._views_ret._vis. + Avg._minutes_ret._vis. +
#     Desktop_views + Mobile_views + smog_index + neg1 + neg2 +
#     neg3 + neg5 + pos1 + pos2 + pos4 + Li_ref + Engaged_hours +
#     Returning_vis_10000 + Search_refs_10000 + Internal_refs_10000 +
#     Other_refs_10000 + Direct_refs_10000 + Fb_refs_10000 + Tw_refs_10000 +
#     Fb_interactions_10000 + total_words_10, family = binomial(link = "logit"),
#     data = train)
m5<-glm(formula = impact ~ Avg._views_ret._vis. + Mobile_views +
smog_index + neg1 + neg2 + neg3 + neg5 + pos1 + pos2 + pos4 +
Li_ref + Engaged_hours + Other_refs_10000 + Fb_interactions_10000 +
total_words_10, family = binomial(link = "logit"), data = train)
