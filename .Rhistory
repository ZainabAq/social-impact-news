politics_s3 = politics_s3 %>%
select(-`Tw refs`, -`Li refs`, -`Pi refs`, -`Tw interactions`, -`Li interactions`, -`Pi interactions`, -ID, -`Social interactions`, -`Social refs`)
NA_find <-as.data.frame(is.na(politics_s3))
View(NA_find)
best.iter
set.seed(5)
fitControl = trainControl(method="cv", summaryFunction =  twoClassSummary, classProbs = TRUE, number = 5, returnResamp = "all")
mp6 <- train(Impact~.-URL -Title, data=politics_boost, method="gbm", trControl=fitControl, tuneGrid=data.frame(.n.trees=best.iter, .shrinkage=0.001, .interaction.depth=1, .n.minobsinnode=1), verbose=FALSE,  metric = "ROC", distribution = "bernoulli")
mp6_estimates = predict(mp6, politics_boost)
confusionMatrix(mp6_estimates, as.factor(politics_boost$Impact))
set.seed(5)
fitControl = trainControl(method="cv", summaryFunction =  twoClassSummary, classProbs = TRUE, number = 5, returnResamp = "all")
mp6 <- train(Impact~.-URL -Title, data=politics_boost, method="gbm", trControl=fitControl, tuneGrid=data.frame(.n.trees=best.iter, .shrinkage=0.01, .interaction.depth=1, .n.minobsinnode=1), verbose=FALSE,  metric = "ROC", distribution = "bernoulli")
varImp(mp6)
mp6_estimates = predict(mp6, politics_boost)
confusionMatrix(mp6_estimates, as.factor(politics_boost$Impact))
confusionMatrix(mp6)
##Accuracy 81.5% CI (0.788, 0.841) Kappa #0.589
postResample(mp6_estimates, as.factor(politics_boost$Impact))
##Accuracy 81.5% CI (0.788, 0.841) Kappa #0.589
postResample(mp6_estimates, as.factor(politics_test$Impact))
##Accuracy 81.5% CI (0.788, 0.841) Kappa #0.589
postResample(mp6_estimates, as.factor(politics_boost_test$Impact))
##Accuracy 81.5% CI (0.788, 0.841) Kappa #0.589
postResample(mp6_estimates, as.factor(politics_boost_train$Impact))
##Accuracy 81.5% CI (0.788, 0.841) Kappa #0.589
postResample(mp6_estimates, as.factor(politics_boost$Impact))
fitControl = trainControl(method="cv", summaryFunction =  twoClassSummary, classProbs = TRUE, number = 5, returnResamp = "all")
mp6 <- train(Impact~.-URL -Title, data=politics_train, method="gbm", trControl=fitControl, tuneGrid=data.frame(.n.trees=best.iter, .shrinkage=0.01, .interaction.depth=1, .n.minobsinnode=1), verbose=FALSE,  metric = "ROC", distribution = "bernoulli")
confusionMatrix(mp6)
mp6_estimates = predict(mp6, politics_test)
mp6_estimates = predict(mp6, politics_boost_test)
politics_s3_text <- read_csv("text-data-nlp-politics.csv")
politics_s3_text = politics_s3_text[1:901,]
politics_s3 <- politics[1:901,]
politics_s3 <- left_join(politics_s3, politics_s3_text, by = "URL")
added_sent <- read_csv("politics_added_sentiment.csv")
added_sent = added_sent %>%
select(URL, neg1, neg2, neg3, neg4, neg5, pos1, pos2, pos3, pos4, pos5)
added_sent = added_sent[1:901,]
politics_s3 <- left_join(politics_s3, added_sent, by = "URL")
politics_s3_rated <- read_csv("politics_rated_for_s3.csv")
politics_s3 <- left_join(politics_s3_rated, politics_s3, by ="URL")
politics_s3 = politics_s3 %>%
select( -text, -`Publish date`, -Authors, -Section, -Tags, -`Sort (Views)`)
politics_s3 = politics_s3 %>%
mutate(Other_Social_ref = `Social refs` - (`Fb refs`+`Tw refs`))%>%
mutate(Li_ref = as.factor(ifelse(is.na(`Li refs`), 0, 1))) %>%
mutate(Pi_ref = as.factor(ifelse(is.na(`Pi refs`), 0, 1))) %>%
mutate(Other_int = `Social interactions` - (`Fb interactions` + `Tw interactions`)) %>%
mutate(Tw_int = as.factor(ifelse(is.na(`Tw interactions`), 0 , 1))) %>%
mutate(Li_int = as.factor(ifelse(is.na(`Li interactions`), 0 , 1))) %>%
mutate(Pi_int = as.factor(ifelse(is.na(`Pi interactions`), 0 , 1)))
politics_s3 = politics_s3 %>%
select(-`Tw refs`, -`Li refs`, -`Pi refs`, -`Tw interactions`, -`Li interactions`, -`Pi interactions`, -ID, -`Social interactions`, -`Social refs`)
NA_find <-as.data.frame(is.na(politics_s3))
politics_s3 <- politics_s3[-c(279, 281, 680, 752, 763, 775),]
dulplicated <- as.data.frame(duplicated(politics_s3) | duplicated(politics_s3, fromLast = TRUE))
politics_s3 <- politics_s3[-c(51, 151, 298, 349, 782, 853),]
##Cleaning data
spaceless <- function(x) {colnames(x) <- gsub(" ", "_", colnames(x));x}
hless <- function(x) {colnames(x) <- gsub("-", "_", colnames(x));x}
politics_s3 <- spaceless(politics_s3)
politics_s3 <- hless(politics_s3)
names(politics_s3)
#Dividing the data into testing and training
politics_s3 <- politics_s3[-441,]
politics_boost <- politics_s3 %>%
mutate(Impact = as.factor(ifelse(impact == 1, "Y", "N" ))) %>%
select(-impact)
set.seed(5)
politics_boost_train <- politics_s3 %>%
sample_frac(0.5)
politics_boost_test <- politics_s3 %>%
set_diff(politics_boost_train)
politics_boost_test <- politics_s3 %>%
setdiff(politics_boost_train)
mp5<- gbm(impact ~ . -URL -Title, data = politics_boost_train, distribution = "bernoulli", n.trees = 2000, cv.folds = 5, verbose = F)
best.iter = gbm.perf(mp5, method = "cv")
best.iter
set.seed(5)
fitControl = trainControl(method="cv", summaryFunction =  twoClassSummary, classProbs = TRUE, number = 5, returnResamp = "all")
mp6 <- train(Impact~.-URL -Title, data=politics_train, method="gbm", trControl=fitControl, verbose=FALSE,  metric = "ROC", distribution = "bernoulli")
varImp(mp6)
confusionMatrix(mp6)
mp6_estimates = predict(mp6, politics_boost_test)
confusionMatrix(mp6_estimates, as.factor(politics_boost$Impact))
politics_boost_test <- politics_s3 %>%
setdiff(politics_boost_train)
mp6_estimates = predict(mp6, politics_boost_test)
politics_s3_text <- read_csv("text-data-nlp-politics.csv")
politics_s3_text = politics_s3_text[1:901,]
politics_s3 <- politics[1:901,]
politics_s3 <- left_join(politics_s3, politics_s3_text, by = "URL")
added_sent <- read_csv("politics_added_sentiment.csv")
added_sent = added_sent %>%
select(URL, neg1, neg2, neg3, neg4, neg5, pos1, pos2, pos3, pos4, pos5)
added_sent = added_sent[1:901,]
politics_s3 <- left_join(politics_s3, added_sent, by = "URL")
politics_s3_rated <- read_csv("politics_rated_for_s3.csv")
politics_s3 <- left_join(politics_s3_rated, politics_s3, by ="URL")
politics_s3 = politics_s3 %>%
select( -text, -`Publish date`, -Authors, -Section, -Tags, -`Sort (Views)`)
politics_s3 = politics_s3 %>%
mutate(Other_Social_ref = `Social refs` - (`Fb refs`+`Tw refs`))%>%
mutate(Li_ref = as.factor(ifelse(is.na(`Li refs`), 0, 1))) %>%
mutate(Pi_ref = as.factor(ifelse(is.na(`Pi refs`), 0, 1))) %>%
mutate(Other_int = `Social interactions` - (`Fb interactions` + `Tw interactions`)) %>%
mutate(Li_int = as.factor(ifelse(is.na(`Li interactions`), 0 , 1))) %>%
mutate(Pi_int = as.factor(ifelse(is.na(`Pi interactions`), 0 , 1)))
politics_s3 = politics_s3 %>%
select( -`Li refs`, -`Pi refs`, -`Li interactions`, -`Pi interactions`, -ID, -`Social interactions`, -`Social refs`)
NA_find <-as.data.frame(is.na(politics_s3))
politics_s3 <- politics_s3[-c(279, 281, 680, 752, 763, 775),]
dulplicated <- as.data.frame(duplicated(politics_s3) | duplicated(politics_s3, fromLast = TRUE))
politics_s3 <- politics_s3[-c(51, 151, 298, 349, 782, 853),]
spaceless <- function(x) {colnames(x) <- gsub(" ", "_", colnames(x));x}
hless <- function(x) {colnames(x) <- gsub("-", "_", colnames(x));x}
politics_s3 <- spaceless(politics_s3)
politics_s3 <- hless(politics_s3)
names(politics_s3)
#Dividing the data into testing and training
politics_s3 <- politics_s3[-441,]
politics_boost <- politics_s3 %>%
mutate(Impact = as.factor(ifelse(impact == 1, "Y", "N" ))) %>%
select(-impact)
set.seed(5)
politics_boost_train <- politics_boost %>%
sample_frac(0.5)
politics_boost_test <- politics_boost %>%
setdiff(politics_boost_train)
set.seed(5)
fitControl = trainControl(method="cv", summaryFunction =  twoClassSummary, classProbs = TRUE, number = 5, returnResamp = "all")
mp6 <- train(Impact~.-URL -Title, data=politics_boost_train, method="gbm", trControl=fitControl, verbose=FALSE,  metric = "ROC", distribution = "bernoulli")
varImp(mp6)
confusionMatrix(mp6)
mp6_estimates = predict(mp6, politics_boost_test)
predictions <- predict(object=mp6, politics_boost, type='prob')
predictions <- predict(object=mp6, politics_boost_test, type='prob')
predictions <- predict(object=mp6, politics_boost_test$Impact, type='prob')
politics_boost <- politics_s3 %>%
mutate(Impact = as.factor(ifelse(impact == 1, "Y", "N" ))) %>%
select(-impact)
set.seed(5)
politics_boost_train <- politics_boost %>%
sample_frac(0.5)
politics_boost_test <- politics_boost %>%
setdiff(politics_boost_train)
set.seed(5)
fitControl = trainControl(method="cv", summaryFunction =  twoClassSummary, classProbs = TRUE, number = 5, returnResamp = "all")
mp6 <- train(Impact~.-URL -Title, data=politics_boost_train, method="gbm", trControl=fitControl, verbose=FALSE,  metric = "ROC", distribution = "bernoulli")
confusionMatrix(mp6)
predictions <- predict(mp6, politics_boost_test$Impact, type='prob')
politics_boost_test
predictions <- predict(mp6, politics_boost_test$Impact, type='prob')
politics_boost_train <- politics_boost %>%
sample_frac(0.5) %>%
select(-URL, -Title)
politics_boost_test <- politics_boost %>%
setdiff(politics_boost_train) %>%
select(-URL, -Title)
predictions <- predict(mp6, politics_boost_test$Impact, type='prob')
mp6 <- train(Impact~ ., data=politics_boost_train, method="gbm", trControl=fitControl, verbose=FALSE,  metric = "ROC", distribution = "bernoulli")
varImp(mp6)
predictions <- predict(mp6, politics_boost_test$Impact, type='prob')
politics_boost_train
set.seed(5)
fitControl = trainControl(method="cv", summaryFunction =  twoClassSummary, classProbs = TRUE, number = 5, returnResamp = "all")
mp6 <- train(Impact~.-URL -Title, data=politics_boost, method="gbm", trControl=fitControl, verbose=FALSE,  metric = "ROC", distribution = "bernoulli")
varImp(mp6)
predictions <- predict(object=mp6, politics_boost, type='raw')
##Accuracy 81.5% CI (0.788, 0.841) Kappa #0.589
postResample(predictions, as.factor(politics_boost$Impact))
postResample(mp6_estimates, as.factor(politics_boost$Impact))
mp6_estimates = predict(mp6, politics_boost_test)
postResample(mp6_estimates, as.factor(politics_boost$Impact))
mp6_estimates = predict(mp6, politics_boost)
mp6_estimates = predict(mp6, politics_boost)
postResample(mp6_estimates, as.factor(politics_boost$Impact))
summary(mp6)
mp6
confusionMatrix(mp6_estimates, as.factor(politics_boost$Impact))
predictions <- predict(object=mp6, politics_boost_test$Impact, type='prob')
predictions <- predict(object=mp6, politics_boost$Impact, type='prob')
mp6 <- train(Impact~.-URL -Title, data=politics_boost, method="gbm", trControl=fitControl, verbose=FALSE,  metric = "ROC", distribution = "bernoulli")
predictions <- predict(object=mp6, politics_boost$Impact, type='prob')
predictions <- predict(object=mp6, as.factor(politics_boost$Impact, type='prob'))
predictions <- predict(object=mp6, as.factor(politics_boost$Impact), type='prob')
predictions <- predict(object=mp6, politics_boost, type='prob')
##Accuracy 81.8% CI (0.788, 0.841) Kappa #0.589
postResample(predictions, as.factor(politics_boost$Impact))
postResample(mp6_estimates, as.factor(politics_boost$Impact))
head(predictions)
#AUC socre
auc = roc(ifelse(politics_boost[,44] == "Y", 1, 0), predictions[[2]])
predictions <- predict(object=mp6, politics_boost$Impact, type='prob')
politics_boost <- politics_s3 %>%
mutate(Impact = as.factor(ifelse(impact == 1, "Y", "N" ))) %>%
select(-impact, - URL, -Title)
mp6 <- train(Impact~., data=politics_boost, method="gbm", trControl=fitControl, verbose=FALSE,  metric = "ROC", distribution = "bernoulli")
predictions <- predict(object=mp6, politics_boost$Impact, type='prob')
politics_boost <- politics_s3 %>%
mutate(Impact = as.factor(ifelse(impact == 1, "Y", "N" ))) %>%
select(-impact)
fitControl = trainControl(method="cv", summaryFunction =  twoClassSummary, classProbs = TRUE, number = 5, returnResamp = "all")
mp6 <- train(Impact~.-URL -Title, data=politics_boost, method="gbm", trControl=fitControl, verbose=FALSE,  metric = "ROC", distribution = "bernoulli")
mp6
confusionMatrix(mp6)
mp6_estimates = predict(mp6, politics_boost)
confusionMatrix(mp6_estimates, as.factor(politics_boost$Impact))
#AUC socre
auc = roc(ifelse(politics_boost[,44] == "Y", 1, 0), predictions[[2]])
print(auc$auc)
mp6 <- train(Impact~.-URL -Title, data=politics_boost, method="gbm", trControl=fitControl, tuneGrid=data.frame(.shrinkage=0.01), verbose=FALSE,  metric = "ROC", distribution = "bernoulli")
trainControl
?trainControl
expand.grid(interaction.depth = c(1, 2, 3),
n.trees = (0:50)*50,
shrinkage = seq(.0005, .05, .0005),
n.minobsinnode = 10)
expand.grid(interaction.depth = c(1, 2, 3),
n.trees = (0:50)*50,
shrinkage = c(.1 ,.01, .001),
n.minobsinnode = 10)
tune = expand.grid(interaction.depth = c(1, 2, 3),
n.trees = (0:50)*50,
shrinkage = c(.1 ,.01, .001),
n.minobsinnode = 10)
class(tune)
mp6 <- train(Impact~.-URL -Title, data=politics_boost, method="gbm", trControl=fitControl, tuneGrid = tune, verbose=FALSE,  metric = "ROC", distribution = "bernoulli")
mp6
tune = expand.grid(interaction.depth = c(1, 2, 3),
n.trees = (0:50)*50,
shrinkage = c(.1 ,.01, .001),
n.minobsinnode = (1:10))
mp6 <- train(Impact~.-URL -Title, data=politics_boost, method="gbm", trControl=fitControl, tuneGrid = tune, verbose=FALSE,  metric = "ROC", distribution = "bernoulli")
mp6
confusionMatrix(mp6)
predictions <- predict(object=mp6, politics_boost, type='raw')
mp6_estimates = predict(mp6, politics_boost)
confusionMatrix(mp6_estimates, as.factor(politics_boost$Impact))
confusionMatrix(predictions,  as.factor(politics_boost$Impact))
##Accuracy 81.8% CI (0.788, 0.841) Kappa #0.589
postResample(predictions, as.factor(politics_boost$Impact))
varImp(mp6)
?vaimp
?varImp
plot(varImp(mp6), nbars = 20)
plot(varImp(mp6), nbars = 10)
?plot
plot(varImp(mp6), top = 20)
plot(varImp(mp6), top = 25)
plot(varImp(mp6), top = 30)
plot(varImp(mp6), top = 35)
plot(varImp(mp6), top = 25)
View(mp6)
mp6[["results"]]
mp6df <-mp6[["results"]]
mp6df %>%
View(mp6df)
View(mp6df)
mp6df %>%
filter(shrinkage == 0.01, interaction.depth == 3, n.trees == 650, n.misobsinnode == 9)
filter(mp6df, shrinkage == 0.01, interaction.depth == 3, n.trees == 650, n.minobsinnode == 9)
pretty.gbm.tree(mp6, i.tree = 300)
pretty.gbm.tree(mp6, i.tree = 1)
pretty.gbm.tree(mp6, i.tree = 0.5)
pretty.gbm.tree(mp6, i.tree = -1)
pretty.gbm.tree(mp6)
?pretty.gbm.tree
pretty.gbm.tree(mp6, 1)
pretty.gbm.tree(mp6, i=1)
class(mp6)
pretty.gbm.tree(mp7, i=1)
plot(mp6, type="simple")
plot(mp6$finalModel)
text(mp6$finalModel)
mp6
plot(mp6$trees)
text(mp6$trees)
mp6$trees
mp6$pred
mp6$pred
rpart1a <- as.party(mp6)
library(party)
rpart1a <- as.party(mp6)
install.packages("partykit")
library("partykit")
rpart1a <- as.party(mp6)
plot(mp6)
plot.train(mp6$finalModel)
class(mp6)
pretty.gbm.tree(mp7, i=1)
plot(pretty.gbm.tree(mp7, i=1))
class(mp0)
View(mp0)
plottree <- as.tree(mp6)
install.packages("rattle")
library(rattle)
library(rattle)
require(ratt;le)
require(rattle)
install.packages("rattle")
library(rattle)
plot(mp6$finalModel)
text(mp6$finalModel)
plot(mp6$finalModel)
plot(mp6$finalModel)
text(mp6$finalModel)
print(mp6)
mp6$trees
politics_tree <- politics_s3 %>%
select(total_words, Views, Social_interactions, Mobile_views, readability, total_sentences, pos3, smog_index, pos1, neg2, Returning_vis., Visitors, Avg._views_new_vis., Avg._views_ret._vis., Table_views, Social_refs, grade_level, pos2, Engaged_minutes, Other_refs, Search_refs, neg3, impact)
politics_tree <- politics_s3 %>%
select(total_words, Views, social_interactions, Mobile_views, readability, total_sentences, pos3, smog_index, pos1, neg2, Returning_vis., Visitors, Avg._views_new_vis., Avg._views_ret._vis., Table_views, Social_refs, grade_level, pos2, Engaged_minutes, Other_refs, Search_refs, neg3, impact)
boost_tree <- tree(as.factor(impact) ~., politics_tree)
summary(boost_tree)
plot(boost_tree)
text(boost_tree, pretty=0)
names(politics_s3)
politics_tree <- politics_s3 %>%
select(total_words, Views, Fb_interactions, Mobile_views, readability, total_sentences, Other_int, Visitors, pos3, Tw_refs, smog_index, neg2, grade_level, pos1, Tw_interactions, Returning_vis., Tablet_views, Avg._views_new_vis., Fb_refs, Engaged_minutes, Other_refs, pos2, Avg._minutes_new_vis., neg1, neg3, impact)
boost_tree <- tree(as.factor(impact) ~., politics_tree)
summary(boost_tree)
plot(boost_tree)
text(boost_tree, pretty=0)
library(rpart)
fitboost <- rpart(as.factor(impact) ~ ., method="class", data=politics_tree)
printcp(fitboost)
plotcp(fitboost)
plot(fitboost, uniform =TRUE)
text(fitboost, use.n=TRUE, all=TRUE, cex=.8)
plot(fitboost, uniform =TRUE)
text(fitboost, use.n=TRUE, all=TRUE, cex=.5)
plot(fitboost, uniform =TRUE)
text(fitboost, use.n=TRUE, all=TRUE, cex=.8)
plot(fitboost, uniform =TRUE)
text(fitboost, use.n=TRUE, all=TRUE, cex=.3)
plot(fitboost, uniform =TRUE)
text(fitboost, use.n=TRUE, all=TRUE, cex=.8)
plot(fitboost, uniform =TRUE)
text(fitboost, use.n=TRUE, all=TRUE, cex=.8, pretty=0)
post(fitboost, file = "c:/tree.ps",
title = "Classification Tree")
fancyRpartPlot(fitboost)
install.packages("rpart.plot")
library(rpart.plot)
prp(fitboost)
plot(fitboost, uniform =TRUE)
text(fitboost, use.n=TRUE, all=TRUE, cex=.8, pretty=0)
?prp
prp(fitboost, type=1, extra=1, nn=TRUE, Margin = 1)
prp(fitboost, type=1, extra=1, nn=TRUE)
plot(fitboost, uniform =TRUE)
text(fitboost, use.n=TRUE, all=TRUE, cex=.8, pretty=0)
prp(fitboost, type=1, extra=1, nn=TRUE, under.col = 3)
prp(fitboost, type=1, extra=1, nn=TRUE, under.col = 3, varlen=10)
prp(fitboost, type=1, extra=1, under.col = 3, varlen=10)
prp(fitboost, type=1, extra=1, under.col = 3, varlen=15)
info.gain.rpart(fit)
plot(boost_tree)
text(boost_tree, pretty=0)
summary(fitboost)
summary(boost_tree)
fitboost
summary(fitboost)
summary(fitboost)
plot(boost_tree)
text(boost_tree, pretty=0)
Turk <- read_csv("Batch_3145287_batch_results.csv")
Turk_time<-Turk %>%
filter(WorkTimeInSeconds >= 29)
tidyTurk <- Turk_time %>%
mutate(y = ifelse(Answer.categories == "category 1", 0, 1)) %>%
group_by(Input.URL) %>%
summarise(ys = paste(y, collapse = ","))%>%
separate(ys, into = c("y1", "y2", "y3"))
corTurk <- tidyTurk %>%
select(y1, y2, y3)
check <- rcorr(as.matrix(corTurk))
check
View(tidyTurk)
View(Turk)
Turk <- read_csv("Batch_3145287_batch_results.csv")
Turk_time<-Turk %>%
filter(WorkTimeInSeconds >= 29)
tidyTurk <- Turk_time %>%
mutate(y = ifelse(Answer.categories == "category 1", 0, 1)) %>%
group_by(Input.URL) %>%
summarise(ys = paste(y, collapse = ","))%>%
separate(ys, into = c("y1", "y2", "y3"))
tidyTurk <- Turk %>%
mutate(y = ifelse(Answer.categories == "category 1", 0, 1)) %>%
group_by(Input.URL) %>%
summarise(ys = paste(y, collapse = ","))%>%
separate(ys, into = c("y1", "y2", "y3"))
corTurk <- tidyTurk %>%
select(y1, y2, y3)
check <- rcorr(as.matrix(corTurk))
check
corr.test(tidyTurk$y1, tidyTurk$y2)
tidyTurk$y1 <- as.numeric(tidyTurk$y1)
tidyTurk$y2 <- as.numeric(tidyTurk$y2)
corr.test(tidyTurk$y1, tidyTurk$y2)
tally(Turk2$V1)
check2 <- corr.test(as.matrix(corTurk))
library(psych)
check2 <- corr.test(as.matrix(corTurk))
check2 <- corr.test(corTurk)
check2 <- corr.test(corTurk)
str(corTurk)
corTurk2 <- as.numeric(corTurk)
corTurk$y1 <- as.numeric(y1)
corTurk$y2 <- as.numeric(y2)
corTurk$y3 <- as.numeric(y3)
corTurk$y1 <- as.numeric(corTurk$y1)
corTurk$y2 <- as.numeric(corTurk$y2)
corTurk$y3 <- as.numeric(corTurk$y3)
check2 <- corr.test(corTurk)
check2
nrow(corTurk)
##Testing for Random
random <- data.frame(replicate(3,sample(0:1,2500,rep=TRUE)))
r <- seq(0,.9,.1)
r
listcheck <- as.list(corTurk)
r.rc <- data.frame(r=listcheck,z=fisherz(r),lower=rc[,1],upper=rc[,2],t=test$t,p=test$p)
r.rc <- data.frame(r=listcheck,z=fisherz(r),lower=check[,1],upper=check[,2],t=test$t,p=test$p)
check[,1]
rc <- matrix(r.con(r,n),ncol=2)
n <- 30
rc <- matrix(r.con(r,n),ncol=2)
rc
check
as.matrix(corTurk)
matrixcheck <- as.matrix(corTurk)
r.rc <- data.frame(r=listcheck,z=fisherz(r),lower=matrix
[,1],upper=matrixcheck[,3],t=test$t,p=test$p)
r.rc <- data.frame(r=listcheck,z=fisherz(r),lower=matrixcheck[,1],upper=matrixcheck[,3],t=test$t,p=test$p)
test <- r.test(2500,check)
r.rc <- data.frame(r=listcheck,z=fisherz(r),lower=matrixcheck[,1],upper=matrixcheck[,3],t=test$t,p=test$p)
test <- r.test(2500,listcheck)
cor.test(corTurk$y1, corTurk$y2, corTurk$y3)
corTurk$y1 <- as.numeric(corTurk$y1)
corTurk$y2 <- as.numeric(corTurk$y2)
corTurk$y3 <- as.numeric(corTurk$y3)
cor.test(corTurk$y1, corTurk$y2, corTurk$y3)
cor.test
?cor.test
cor.test(corTurk)
str(corTurk)
cor.test(corTurk$y1, corTurk$y2)
cor.test(corTurk$y1, corTurk$y2, corTurk$y2)
cor.test(corTurk$y1, corTurk$y3)
cor.test(corTurk$y2, corTurk$y3)
check2
random
cor.test(random$X1, random$X2)
cor.test(random$X1, random$X3)
cor.test(random$X2, random$X3)
cor.test(corTurk$y1, corTurk$y2)
cor.test(corTurk$y1, corTurk$y3)
check2
cor.test(corTurk$y2, corTurk$y3)
?cor.test
cor.test(corTurk$y1, corTurk$y2, alternative = "two.sided" )
cor.test(corTurk$y1, corTurk$y3, alternative = "two.sided")
cor.test(corTurk$y2, corTurk$y3, alternative = "two.sided")
cor.test(corTurk$y1, corTurk$y2, alternative = "two.sided", method = c("pearson", "kendall", "spearman") )
cor.test(corTurk$y1, corTurk$y3, alternative = "two.sided", , method = c("pearson", "kendall", "spearman"))
cor.test(corTurk$y2, corTurk$y3, alternative = "two.sided", , method = c("pearson", "kendall", "spearman"))
cor.test(corTurk$y1, corTurk$y2, alternative = "two.sided", method =  "kendall")
cor.test(corTurk$y1, corTurk$y3, alternative = "two.sided", method = "kendall")
cor.test(corTurk$y2, corTurk$y3, alternative = "two.sided", method = "kendall")
cor.test(corTurk$y1, corTurk$y2, alternative = "two.sided", method =  "spearman")
cor.test(corTurk$y1, corTurk$y3, alternative = "two.sided", method = "spearman")
cor.test(corTurk$y2, corTurk$y3, alternative = "two.sided", method = "spearman")
cor.test(corTurk$y1, corTurk$y2, alternative = "two.sided")
cor.test(corTurk$y1, corTurk$y3, alternative = "two.sided")
cor.test(corTurk$y2, corTurk$y3, alternative = "two.sided")
cor.test(corTurk$y1, corTurk$y2, alternative = "two.sided")
cor.test(random$X1, random$X2)
rtest(n=2500, r12=0.02238351, r13=-0.03225803)
r.test(n=2500, r12=0.02238351, r13=-0.03225803)
summary(r.test(n=2500, r12=0.02238351, r13=-0.03225803))
print(r.test(n=2500, r12=0.02238351, r13=-0.03225803))
print(r.test(n=2500, 0.02238351, -0.03225803))
cor.test(corTurk$y1, corTurk$y3, alternative = "two.sided")
cor.test(random$X1, random$X3)
print(r.test(n=2500, 0.0487411, -0.01529797))
cor.test(corTurk$y2, corTurk$y3, alternative = "two.sided")
cor.test(random$X2, random$X3)
print(r.test(n=2500, 0.03599165, 0.009449315))
print(r.test(n=2500, 0.02238351, -0.03225803))
print(r.test(n=2500, 0.0487411, -0.01529797))
print(r.test(n=2500, 0.03599165, 0.009449315))
print(r.test(n=2500, 0.02238351, -0.03225803))
print(r.test(n=2500, 0.0487411, -0.01529797))
print(r.test(n=2500, 0.03599165, 0.009449315))
politics_mkfinal100 <- politics[1101:1200,]
write.csv(politics_mkfinal100, file="politics_mk_final_100.csv", sep = ",", row.names=F)
?log
library(readr)
library(dplyr)
library(tidyr)
library(stringr)
library(ggplot2)
library(plotly)
library(ISLR)
library(data.table)
library(mosaic)
library(ggthemes)
