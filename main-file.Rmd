---
title: "main-file"
output: html_document
editor_options: 
  chunk_output_type: inline
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Remains the same for everyone
```{r}
library(readr)
# change this according to your
data_10000 <- read_csv("Raw data_10000 articles_Jul-Dec 2017.csv")
```


# Sections for everyone

# Minji

```{r}
library(dplyr)
library(mosaic)
library(randomForest)
library(ParetoPosStable)
library(tree)
library(gbm)
library(adabag)
library(EnvStats)
library(caret)
library(Hmisc)

##removing na's and creating the existing metric
Sint_PV <- data_10000%>%
  mutate(metric = `Social interactions`/Views)%>%
  arrange(desc(metric))%>%
  na.omit(`Engaged minutes`)%>%
  na.omit(`Social interactions`)

##creating vectors 
engaged_min <- Sint_PV$`Engaged minutes`
metric <-Sint_PV$metric
soc_int <- Sint_PV$`Social interactions`
pv <-as.data.frame(Sint_PV$`Views`) 
V <-Sint_PV$`Views`
rv <- Sint_PV$`Returning vis.`


##Pareto Distribution
pareto.fit(V, estim.method = "MLE")

ggplot(pv, aes(log(V))) + geom_histogram(aes(y=..density..), bins = 100 ) + stat_function(fun = dnorm, args = list(11.68749, 1.013802), color = "red")

p <- ggplot(pv, aes(V)) + geom_histogram(aes(y=..density..), bins = 100) 
p+ stat_function(fun = dpareto, args = list(7795, 0.4751), color = "red")

###################################################################################################

merged_200 <- read_csv("merged_200.csv")
minji_50 <- merged_200[101:150,]
write.table(minji_50, file="minji_50.csv",sep=",",row.names=F)
minji_50_impact <- read_csv("minji_50_impact.csv")
rated_200 <- read_csv("rated_200.csv")
tally(~Section, data_10000)
politics <- data_10000 %>%
  filter(Section == "Politics")
politics <- politics[151:225,]
write.table(politics, file="politics.csv", sep =",", row.names=F)
#politics_75 <-read_csv("text-data-politics.csv")
#politics_75 <- politics_75[151:225,]
#write.table(politics_75, file="politics_75.csv", sep=",",row.names=F)
###################################################################################################

rated_200 <- rated_200 %>%
  mutate(Impact1 = ifelse(Impact == 9, 1, ifelse(Impact == 1, 1, 0)))%>%
  select(-Impact)


##Cleaning Data before Modeling 
spaceless <- function(x) {colnames(x) <- gsub(" ", "_", colnames(x));x}
hless <- function(x) {colnames(x) <- gsub("-", "_", colnames(x));x}
clean_200 <- spaceless(rated_200)
clean_200 <- hless(clean_200)
clean_200 <- na.omit(clean_200)

##Classification Tree of the whole dataset
tree <- tree(as.factor(Impact1) ~. -Tags -`Sort_(Views)` -text -keywords -summary -URL -Title -Authors -Section -Publish_date -X1 , clean_200 )
head(clean_200)
summary(tree)
plot(tree)
text(tree, pretty=0)

#Dividing the data into testing and training
set.seed(5)
clean_train <- clean_200 %>%
  sample_frac(0.5)

clean_test <- clean_200%>%
  setdiff(clean_train)

##Random Forest model 
set.seed(5)
m0 <- randomForest(as.factor(Impact1) ~. -Tags -`Sort_(Views)` -text -keywords -summary -URL -Title -Authors -Section -Publish_date -X1, data=clean_train, importance = TRUE, ntree=2000, mtry=5)
varImpPlot(m0)

m0_estimates = predict(m0, newdata = clean_test, n.trees = 2000) 

table(m0_estimates, clean_test$Impact1)

(17+23)/64 ##60.9% correct predictions.


##Random Forest model with Conditional inference (uses statistical test rather than purity)
set.seed(5)
m1 <- randomForest(as.factor(Impact1) ~. -Tags -`Sort_(Views)` -text -keywords -summary -URL -Title -Authors -Section -Publish_date -X1, data=clean_train, controls=cforest_unbiased(ntree=2000, mtry=5))
varImpPlot(m1)

m1_estimates = predict(m1, newdata = clean_test, OOB=TRUE, type = "response") 
table(m1_estimates, clean_test$Impact1)
(15+22)/64 ##62.5 correct predictions

##Classication tree
set.seed(5)
m2 <- tree(as.factor(Impact1) ~ . -Tags -`Sort_(Views)` -text -keywords -summary -URL -Title -Authors -Section -Publish_date -X1, data=clean_train)
summary(m2)
plot(m2)
text(m2, pretty = 0)
m2_estimates = predict(m2, clean_test, type = "class")
table(m2_estimates, clean_test$Impact1)
(22+19)/64 ##64.1% correct predictions 

##Pruned tree with CV 
set.seed(5)
m3 <- cv.tree(m2, FUN = prune.misclass)
plot(m3$size, m3$dev, type = "b")
m4 <- prune.misclass(m2, best = 5)
plot(m4)
text(m4, pretty = 0)
m4_estimates = predict(m4, clean_test, type = "class")
table(m4_estimates, clean_test$Impact1)
(22+21)/64 ##67.2% correct predictions

##Boosting with Classification 
clean_boost <- clean_200 %>%
  select( -Tags, -`Sort_(Views)`, -text, -keywords, -summary, -URL, -Title, -Authors, -Staection, -Publish_date, -X1)

m5<- gbm(Impact1 ~., data = clean_boost, distribution = "bernoulli", n.trees = 500, cv.folds = 5, verbose = F)
best.iter = gbm.perf(m5, method = "cv")

clean_boost2 <- clean_boost %>%
  mutate(Impact = ifelse(Impact1 == 1, "Y", "N" )) %>%
  select(-Impact1)

m7 <- gbm(Impact1 ~., data = clean_boost, distribution = "bernoulli", cv.folds = 5, verbose = F, shrinkage = 0.01, interaction.depth = 1, n.trees = best.iter, n.minobsinnode = 1)
summary(m7)

set.seed(5)
fitControl = trainControl(method="cv", summaryFunction =  twoClassSummary, classProbs = TRUE, number = 5, returnResamp = "all")
m6 <- train(Impact~., data=clean_boost2, method="gbm", trControl=fitControl, tuneGrid=data.frame(.n.trees=best.iter, .shrinkage=0.01, .interaction.depth=1, .n.minobsinnode=1), verbose=FALSE,  metric = "ROC", distribution = "bernoulli")
m6
confusionMatrix(m6)
confusionMatrix(m6_estimates, as.factor(clean_boost2$Impact))
m6_estimates = predict(m6, clean_boost2)
postResample(m6_estimates, as.factor(clean_boost2$Impact))
##Accuracy 0.859, avg = 0.74


###################################################################################################

##Merging Data
politics_300 <- read_csv("text-stats-politics-300.csv")
politics_ <- data_10000 %>%
  filter(Section == "Politics")
politics_2 <- politics[1:300,]
politics_300 <- left_join(politics_300, politics_2, by = "URL")
write.table(politics_300, file="politics-300-merged.csv", sep =",", row.names=F)
politics_300 <- politics_300 %>% 
  na.omit()%>% 
  select(-ID, -URL, -text, -`Publish date`, -Authors, -Section, -Tags, -`Sort (Views)` , -Title)
write.table(politics_300, file="politics-no-text-merged.csv", sep =",", row.names=F)


##Cleaning data 
spaceless <- function(x) {colnames(x) <- gsub(" ", "_", colnames(x));x}
hless <- function(x) {colnames(x) <- gsub("-", "_", colnames(x));x}
politics_300 <- spaceless(politics_300)
politics_300 <- hless(politics_300)
names(politics_300)
#politics_300 <- politics_300 %>%
  #mutate(metric = Social_interactions/Views)

##Classification Tree of the whole dataset
tree_p <- tree(as.factor(impact_score) ~., politics_300)
summary(tree_p)
plot(tree_p)
text(tree_p, pretty=0)

#Dividing the data into testing and training
set.seed(5)
politics_train <- politics_300 %>%
  sample_frac(0.5)

politics_test <- politics_300%>%
  setdiff(politics_train)

##Classication tree
set.seed(5)
mp0 <- tree(as.factor(impact_score) ~ ., data=politics_train)
summary(mp0)
plot(mp0)
text(mp0, pretty = 0)
mp0_estimates = predict(mp0, politics_test, type = "class")
table(mp0_estimates, politics_test$impact_score)
(49+27)/115 ##66% correct predictions 

##Pruned tree with CV 
set.seed(5)
mp1 <- cv.tree(mp0, FUN = prune.misclass)
plot(mp1$size, mp1$dev, type = "b")
mp2 <- prune.misclass(mp0, best = 5)
plot(mp2)
text(mp2, pretty = 0)
mp2_estimates = predict(mp2, politics_test, type = "class")
table(mp2_estimates, politics_test$impact_score)
(56+26)/115 ##71.3% correct predictions


##Random Forest model 
set.seed(5)
mp3 <- randomForest(as.factor(impact_score) ~.,data=politics_train, importance = TRUE, ntree=2000, mtry=5)
varImpPlot(mp3)
mp3_estimates = predict(mp3, newdata = politics_test, n.trees = 2000) 
table(mp3_estimates, politics_test$impact_score)
(60+15)/115 ##65.2% correct predictions


##Random Forest model with Conditional inference (uses statistical test rather than purity)
set.seed(5)
mp4 <- randomForest(as.factor(impact_score) ~. , data=politics_train, controls=cforest_unbiased(ntree=2000, mtry=5))
varImpPlot(mp4)
mp4_estimates = predict(mp4, newdata = politics_test, type = "response") 
table(mp4_estimates, politics_test$impact_score)
(61+16)/115 ##67 correct predictions



##Boosting with Classification 
mp5<- gbm(impact_score ~., data = politics_300, distribution = "bernoulli", n.trees = 2000, cv.folds = 5, verbose = F)
best.iter = gbm.perf(mp5, method = "cv")

politics_boost <- politics_300 %>%
  mutate(Impact = ifelse(impact_score == 1, "Y", "N" )) %>%
  select(-impact_score)

mp7 <- gbm(impact_score ~., data = politics_300, distribution = "bernoulli", cv.folds = 5, verbose = F, shrinkage = 0.01, interaction.depth = 1, n.trees = best.iter, n.minobsinnode = 1)
summary(mp7)

set.seed(5)
fitControl = trainControl(method="cv", summaryFunction =  twoClassSummary, classProbs = TRUE, number = 5, returnResamp = "all")
mp6 <- train(Impact~., data=politics_boost, method="gbm", trControl=fitControl, tuneGrid=data.frame(.n.trees=best.iter, .shrinkage=0.01, .interaction.depth=1, .n.minobsinnode=1), verbose=FALSE,  metric = "ROC", distribution = "bernoulli")
varImp(mp6)

confusionMatrix(mp6)
mp6_estimates = predict(mp6, politics_boost)
confusionMatrix(mp6_estimates, as.factor(politics_boost$Impact))
postResample(mp6_estimates, as.factor(politics_boost$Impact))
##Accuracy 0.909, (0.8638, 0.9426)

###############################################################
politics_url <- data_10000 %>%
  filter(Section == "Politics") %>% 
  select(URL) 

politics_url <- politics_url[1:2500,]
write.table(politics_url, file="politics-url.csv", sep =",", row.names=F)

Turk <- read_csv("Batch_3145287_batch_results.csv")
######################################

Turk30<-Turk %>%
  filter(WorkTimeInSeconds >= 30)

tidyTurk <- Turk30 %>% 
  mutate(y = ifelse(Answer.categories == "category 1", 0, 1)) %>%
  group_by(Input.URL) %>%
  summarise(ys = paste(y, collapse = ","))%>%
  separate(ys, into = c("y1", "y2", "y3"))

corTurk <- tidyTurk %>%
  select(y1, y2, y3)

check <- rcorr(as.matrix(corTurk))
check
```


# Erina

```{r}
# data_1000_EF<- read_csv("Raw data_10000 articles_Jul-Dec 2017.csv")
# names(data_1000_EF)
# lm1 <- lm(log(`Engaged minutes`)~.-URL-Title-Authors-Tags,data=data_1000_EF)
# summary(lm1)
# anova(lm1)
# 
# plot(lm1)
# summary(data_1000_EF)

library(readr)
library(tidytext)
library(dplyr)
library(stringr)

data_EF <- read_csv("Raw data_10000 articles_Jul-Dec 2017.csv") #import original data

data("stop_words") #import stop words
text <- read_csv("text-data.csv") %>%
  select(URL, article) #import textual data

text$article<- str_replace_all(text$article, "[[:punct:]]", "") #omit special characters
afinn <- get_sentiments("afinn")

afinn_neg5 <- get_sentiments("afinn") %>%
    filter(score == -5)
afinn_neg4 <- get_sentiments("afinn") %>%
    filter(score == -4)
afinn_neg3 <- get_sentiments("afinn") %>%
    filter(score == -3)
afinn_neg2 <- get_sentiments("afinn") %>%
    filter(score == -2)
afinn_neg1 <- get_sentiments("afinn") %>%
    filter(score == -1)
afinn_0 <- get_sentiments("afinn") %>%
    filter(score == 0)
afinn_pos1 <- get_sentiments("afinn") %>%
    filter(score == 1)
afinn_pos2 <- get_sentiments("afinn") %>%
    filter(score == 2)
afinn_pos3 <- get_sentiments("afinn") %>%
    filter(score == 3)
afinn_pos4 <- get_sentiments("afinn") %>%
    filter(score == 4)
afinn_pos5 <- get_sentiments("afinn") %>%
    filter(score == 5)


words <- text %>%
#  group_by(URL) %>%
  unnest_tokens(word, article)

words <- words %>%
  anti_join(stop_words)

neg5 <- words %>%
  group_by(URL) %>%
	inner_join(afinn_neg5) %>%
	count(word, sort=TRUE)

neg4 <- words %>%
  group_by(URL) %>%
	inner_join(afinn_neg4) %>%
	count(word, sort=TRUE)

neg3 <- words %>%
  group_by(URL) %>%
	inner_join(afinn_neg3) %>%
	count(word, sort=TRUE)

neg2 <- words %>%
  group_by(URL) %>%
	inner_join(afinn_neg2) %>%
	count(word, sort=TRUE)

neg1 <- words %>%
  group_by(URL) %>%
	inner_join(afinn_neg1) %>%
	count(word, sort=TRUE)

zero <- words %>%
  group_by(URL) %>%
	inner_join(afinn_0) %>%
	count(word, sort=TRUE)

pos1 <- words %>%
  group_by(URL) %>%
	inner_join(afinn_pos1) %>%
	count(word, sort=TRUE)

pos2 <- words %>%
  group_by(URL) %>%
	inner_join(afinn_pos2) %>%
	count(word, sort=TRUE)

pos3 <- words %>%
  group_by(URL) %>%
	inner_join(afinn_pos3) %>%
	count(word, sort=TRUE)

pos4 <- words %>%
  group_by(URL) %>%
	inner_join(afinn_pos4) %>%
	count(word, sort=TRUE)

pos5 <- words %>%
  group_by(URL) %>%
	inner_join(afinn_pos5) %>%
	count(word, sort=TRUE)

###at "2.2 Sentiment analysis with inner join"
```


```{r}
#####Erina continued



words %>%
	group_by(URL) %>%
	inner_join() %>%
	count(word, sort=TRUE)

words %>%
	group_by(URL) %>%
	inner_join(afinn_neg5) %>%
	count(word, sort=TRUE)

words <- words %>%
  group_by(URL) %>%
  mutate(proportion = n / sum(n))

words <- words%>%
  count(word, sort = TRUE) %>%
  #select(-n) %>% 
  spread(URL, proportion) %>% 
  gather(URL, proportion, 2:3)



#words %>%
 # group_by(article) %>%
  #count(word, sort = TRUE) 
ggplot2::ggplot(data = test, aes(`huff_metric`)) + geom_histogram()

ggplot(test, aes(`huff_metric`)) + 
    geom_histogram(aes(y=..density..),fill="gray40") +
    geom_density(alpha=.2, color = "red")

ggplot(data = test, aes(log(`huff_metric`))) + geom_histogram()

ggplot(test, aes(log(`huff_metric`))) + 
    geom_histogram(aes(y=..density..),fill="gray40") +
    geom_density(alpha=.2, color = "red")
  #testing normality
qqnorm(test$log_huff_metric)
qqline(test$log_huff_metric, col = "red")

#write.csv(text, file = "C:/Users/choco/Desktop/SPRING 2018/Capstone/text_cleanedinR.csv") #create new csv file
```

Social impact:change in way of thinking/attitude or brings someone to take action or change the way they act; leaves an impression or makes the reader think even if it doesn’t change his or her views
Quality Journalism:accurate, clear, multiple sources, relevance, change in way of thinking/attitude/action (includes above)
_Social impact can be a smaller part of quality journalism but not vice versa?_
https://www.huffingtonpost.com/2012/04/16/huffington-post-pulitzer-prize-2012_n_1429169.html


# Julianna 

```{r}
data_10000 %>%
  arrange(`Engaged minutes`) %>%
  select(Title)

ggplot(data = data_10000, aes(log(`Social interactions`))) + geom_histogram()

ggplot(data = data_10000, aes(log(`Views`))) + geom_histogram()

ggplot(data = data_10000, aes(`Views`)) + geom_histogram()

test <- data_10000 %>%
  mutate(`huff_metric` = `Social interactions`/ `Views`, log_huff_metric = log(huff_metric)) %>%
  arrange(desc(huff_metric))

fav_stats(test$log_huff_metric)

ggplot(data = test, aes(log(`huff_metric`))) + geom_histogram()

ggplot(data = test, aes(x = log(`Social interactions`), y = log(`Engaged minutes`))) + geom_point() + 
  geom_smooth()

test <- test %>%
  mutate(log_social_interactions = log(`Social interactions`), log_engaged_minutes = log(`Engaged minutes`), log_views = log(`Views`))

cor(test$log_social_interactions, test$log_engaged_minutes, use = "complete.obs")

qqnorm(test$log_huff_metric)
qqline(test$log_huff_metric, col = "red")

qqnorm(test$log_social_interactions)
qqline(test$log_social_interactions, col = "red")

qqnorm(test$Views)
qqline(test$Views, col = "red")

qqnorm(test$log_views)
qqline(test$log_views, col = "red")

##MODELS--------------------------------------------------

#Finding predictors from backward and stepwise regression
fullmodel <- lm(`huff_metric`~`Views`+`Engaged minutes`+`Returning vis.`+`New vis.`+`Social refs`+`Social interactions`+`Avg. minutes new vis.`+`Avg. minutes ret. vis.`+`Visitors`+`Avg. views new vis.`+`Avg. views ret. vis.`, data = test)

#Using log variables
fullmodel <- lm(log_huff_metric~`Views`+log_engaged_minutes+`Returning vis.`+`New vis.`+`Social refs`+log_social_interactions+`Avg. minutes new vis.`+`Avg. minutes ret. vis.`+`Visitors`+`Avg. views new vis.`+`Avg. views ret. vis.`, data = test)


# backward
fullMSE <- (summary(fullmodel)$sigma)^2
step(fullmodel, data = test, scale = fullMSE, direction = "backward")

test<-na.omit(test)
#stepwise
nullmodel <- lm(`huff_metric` ~ 1, data = test)
step(nullmodel, scope = list(upper = fullmodel),
scale = fullMSE, direction = "both")

#Stepwise gave me this model:
mod_huff <- lm(formula = huff_metric ~ `Social interactions` + `Avg. minutes ret. vis.` + 
    `Returning vis.` + `Engaged minutes` + `New vis.` + `Social refs` + 
    Views + `Avg. views new vis.`, data = test)

summary(mod_huff)

plot(mod_huff)

  #cor matrix for the model
selected_data_mod_step <- test %>%
  select(`Social interactions`, `Avg. minutes ret. vis.`, 
    `Returning vis.`, `Engaged minutes`, `New vis.`, `Social refs`, 
    Views, `Avg. views new vis.`)

  #Nothing abnormally high except (engaged min and returning visitors), (new vis and views), (Social refs and views)
res2 <- rcorr(as.matrix(selected_data_mod_step))
res2

  #checking VIF
library(car)
vif(mod_huff)
#There are big issues of multicollinearity in this model

##How about best subset approach?
library(leaps)

allsubset<-regsubsets(`huff_metric`~`Views`+`Engaged minutes`+`Returning vis.`+`New vis.`+`Social refs`+`Social interactions`+`Avg. minutes new vis.`+`Avg. minutes ret. vis.`+`Visitors`+`Avg. views new vis.`+`Avg. views ret. vis.`, data = test)
options(digits=3)

summary(allsubset)$adjr2
plot(allsubset,scale="adjr2")

summary(allsubset)$cp
plot(allsubset,scale="Cp")

#Using log variables
allsubset_log<-regsubsets(log_huff_metric~`Views`+`Engaged minutes`+`Returning vis.`+`New vis.`+`Social refs`+`Social interactions`+`Avg. minutes new vis.`+`Avg. minutes ret. vis.`+`Visitors`+`Avg. views new vis.`+`Avg. views ret. vis.`, data = test)
options(digits=3)

summary(allsubset_log)$adjr2
plot(allsubset_log,scale="adjr2")

summary(allsubset_log)$cp
plot(allsubset_log,scale="Cp")

#Gives us THIS model:
mod_all <- lm(`huff_metric`~`Views`+`Engaged minutes`+`Returning vis.`+`New vis.`+`Social interactions`+`Social refs`+`Avg. minutes ret. vis.`, data = test)

summary(mod_all)

#Log
mod_all_log <- lm(log_huff_metric~`Views`+`Returning vis.`+`New vis.`+`Social refs`+`Social interactions`+`Avg. minutes ret. vis.`+ `Avg. minutes new vis.`+Visitors, data = test)

summary(mod_all_log)

car::vif(mod_all_log)

plot(mod_all_log)

  #Checking for multicollinearity again
selected_data_mod_best <- test %>%
  select(`Views`,`Engaged minutes`,`Returning vis.`,`New vis.`,`Social refs`,`Social interactions`,`Avg. minutes ret. vis.`)

library(Hmisc)
res2 <- rcorr(as.matrix(selected_data_mod_best))
res2

car::vif(mod_all)

plot(mod_all)
  #Way better with multicollinearity!

#checking section
mod_all_sec1 <- lm(`huff_metric`~`Views`+`Engaged minutes`+`Returning vis.`+`New vis.`+`Social refs`+`Social interactions`+`Avg. minutes ret. vis.`+ `Avg. views new vis.`+Section, data = test)

summary(mod_all_sec1)

test_comb_section <- test %>%
  mutate(black_voices = ifelse(Section == "Black Voices", "yes", "no"))
#what happens when I add that to the model?
mod_all_sec <- lm(`huff_metric`~`Views`+`Engaged minutes`+`Returning vis.`+`New vis.`+`Social refs`+`Social interactions`+`Avg. minutes ret. vis.`+ `Avg. views new vis.`+black_voices, data = test_comb_section)

#This should be something we consider. Do sections fit into theoretical definition of social impact?

##how about engaged minutes per viewer?
test <- test %>%
  mutate(engaged_min_per_view = `Engaged minutes`/Views, engaged_min_per_ret_vis = `Engaged minutes`/`Returning vis.`)%>%
  arrange(desc(engaged_min_per_ret_vis))

mosaic::favstats(test$engaged_min_per_view)

ggplot(test, aes(engaged_min_per_view)) + geom_histogram()

mosaic::favstats(test$engaged_min_per_ret_vis)

ggplot(test, aes(log(engaged_min_per_ret_vis))) + geom_histogram()

```


# Zainab

```{r}
require(mosaic)
favstats(data_10000$Views)

c <- ggplot(data_10000, aes(Views))
c+geom_histogram()

fav_stats(data_10000$`Engaged minutes`)
d <- ggplot(data_10000, aes(`Engaged minutes`))
d+geom_histogram()

ggplot(data_10000, aes_string(x = "`Social refs`", y = "`Engaged minutes`")) +
  theme_bw() +
  geom_jitter()

ggplot(data_10000, aes_string(x = "`Returning vis.`", y = "`Engaged minutes`")) +
  theme_bw() +
  geom_jitter()

ggplot(data_10000, aes_string(x = "Visitors", y = "`Engaged minutes`")) +
  theme_bw() +
  geom_jitter()

data_10000 = data_10000 %>%
  mutate(logEngMins = log(`Engaged minutes`))

data_10000 = data_10000 %>%
  mutate(logRetVisitors = log(`Returning vis.`))

ggplot(data_10000, aes_string(x = "logRetVisitors", y = "logEngMins")) +
  theme_bw() +
  geom_jitter()

c <- ggplot(data_10000, aes(logRetVisitors))
c+geom_histogram()

f <- ggplot(data_10000, aes(logEngMins))
f+geom_histogram()

ggplot(data_10000, aes_string(x = "`Social refs`", y = "Visitors")) +
  theme_bw() +
  geom_jitter()

ggplot(data_10000, aes_string(x = "`Social refs`", y = "`New vis.`")) +
  theme_bw() +
  geom_jitter()


data_10000 %>%
  select(c(`Returning vis.`,`Social refs`, `Engaged minutes`, `Avg. views new vis.`, Views, Visitors, `New vis.`))%>%
  cor()
```


