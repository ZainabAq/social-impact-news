---
title: "main-file"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Remains the same for everyone
```{r}
library(readr)
# change this according to your
data_10000 <- read_csv("Raw data_10000 articles_Jul-Dec 2017.csv")
politics = data_10000 %>% 
  filter(Section == "Politics")
```


# Sections for everyone

# Minji

```{r}
library(dplyr)
library(mosaic)
library(randomForest)
library(ParetoPosStable)
library(tree)
library(caret)
library(gbm)
library(adabag)
library(EnvStats)
library(Hmisc)
library(tidyr)

##removing na's and creating the existing metric
Sint_PV <- data_10000%>%
  mutate(metric = `Social interactions`/Views)%>%
  arrange(desc(metric))%>%
  na.omit(`Engaged minutes`)%>%
  na.omit(`Social interactions`)

##creating vectors 
engaged_min <- Sint_PV$`Engaged minutes`
metric <-Sint_PV$metric
soc_int <- Sint_PV$`Social interactions`
pv <-as.data.frame(Sint_PV$`Views`) 
V <-Sint_PV$`Views`
rv <- Sint_PV$`Returning vis.`


##Pareto Distribution
pareto.fit(V, estim.method = "MLE")

ggplot(pv, aes(log(V))) + geom_histogram(aes(y=..density..), bins = 100 ) + stat_function(fun = dnorm, args = list(11.68749, 1.013802), color = "red")

p <- ggplot(pv, aes(V)) + geom_histogram(aes(y=..density..), bins = 100) 
p+ stat_function(fun = dpareto, args = list(7795, 0.4751), color = "red")

###################################################################################################

merged_200 <- read_csv("merged_200.csv")
minji_50 <- merged_200[101:150,]
write.table(minji_50, file="minji_50.csv",sep=",",row.names=F)
minji_50_impact <- read_csv("minji_50_impact.csv")
rated_200 <- read_csv("rated_200.csv")
tally(~Section, data_10000)
politics <- data_10000 %>%
  filter(Section == "Politics")
write.table(politics, file="politics.csv", sep =",", row.names=F)

#politics_75 <-read_csv("text-data-politics.csv")
#politics_75 <- politics_75[151:225,]
#write.table(politics_75, file="politics_75.csv", sep=",",row.names=F)
####################################################################################################################

#politics_75 <-read_csv("text-data-politics.csv")
#politics_75 <- politics_75[151:225,]
#write.table(politics_75, file="politics_75.csv", sep=",",row.names=F)

###################################################################################################


rated_200 <- rated_200 %>%
  mutate(Impact1 = ifelse(Impact == 9, 1, ifelse(Impact == 1, 1, 0)))%>%
  select(-Impact)


##Cleaning Data before Modeling 
spaceless <- function(x) {colnames(x) <- gsub(" ", "_", colnames(x));x}
hless <- function(x) {colnames(x) <- gsub("-", "_", colnames(x));x}
clean_200 <- spaceless(rated_200)
clean_200 <- hless(clean_200)
clean_200 <- na.omit(clean_200)

##Classification Tree of the whole dataset
tree <- tree(as.factor(Impact1) ~. -Tags -`Sort_(Views)` -text -keywords -summary -URL -Title -Authors -Section -Publish_date -X1 , clean_200 )
head(clean_200)
summary(tree)
plot(tree)
text(tree, pretty=0)

#Dividing the data into testing and training
set.seed(5)
clean_train <- clean_200 %>%
  sample_frac(0.5)

clean_test <- clean_200%>%
  setdiff(clean_train)

##Random Forest model 
set.seed(5)
m0 <- randomForest(as.factor(Impact1) ~. -Tags -`Sort_(Views)` -text -keywords -summary -URL -Title -Authors -Section -Publish_date -X1, data=clean_train, importance = TRUE, ntree=2000, mtry=5)
varImpPlot(m0)

m0_estimates = predict(m0, newdata = clean_test, n.trees = 2000) 

table(m0_estimates, clean_test$Impact1)

(17+23)/64 ##60.9% correct predictions.


##Random Forest model with Conditional inference (uses statistical test rather than purity)
set.seed(5)
m1 <- randomForest(as.factor(Impact1) ~. -Tags -`Sort_(Views)` -text -keywords -summary -URL -Title -Authors -Section -Publish_date -X1, data=clean_train, controls=cforest_unbiased(ntree=2000, mtry=5))
varImpPlot(m1)

m1_estimates = predict(m1, newdata = clean_test, OOB=TRUE, type = "response") 
table(m1_estimates, clean_test$Impact1)
(15+22)/64 ##62.5 correct predictions

##Classication tree
set.seed(5)
m2 <- tree(as.factor(Impact1) ~ . -Tags -`Sort_(Views)` -text -keywords -summary -URL -Title -Authors -Section -Publish_date -X1, data=clean_train)
summary(m2)
plot(m2)
text(m2, pretty = 0)
m2_estimates = predict(m2, clean_test, type = "class")
table(m2_estimates, clean_test$Impact1)
(22+19)/64 ##64.1% correct predictions 

##Pruned tree with CV 
set.seed(5)
m3 <- cv.tree(m2, FUN = prune.misclass)
plot(m3$size, m3$dev, type = "b")
m4 <- prune.misclass(m2, best = 5)
plot(m4)
text(m4, pretty = 0)
m4_estimates = predict(m4, clean_test, type = "class")
table(m4_estimates, clean_test$Impact1)
(22+21)/64 ##67.2% correct predictions

##Boosting with Classification 
clean_boost <- clean_200 %>%
  select( -Tags, -`Sort_(Views)`, -text, -keywords, -summary, -URL, -Title, -Authors, -Section, -Publish_date, -X1)

m5<- gbm(Impact1 ~., data = clean_boost, distribution = "bernoulli", n.trees = 500, cv.folds = 5, verbose = F)
best.iter = gbm.perf(m5, method = "cv")

clean_boost2 <- clean_boost %>%
  mutate(Impact = ifelse(Impact1 == 1, "Y", "N" )) %>%
  select(-Impact1)

set.seed(5)
fitControl = trainControl(method="cv", summaryFunction =  twoClassSummary, classProbs = TRUE, number = 5, returnResamp = "all")
m6 <- train(Impact~., data=clean_boost2, method="gbm", trControl=fitControl, tuneGrid=data.frame(.n.trees=best.iter, .shrinkage=0.01, .interaction.depth=1, .n.minobsinnode=1), verbose=FALSE,  metric = "ROC", distribution = "bernoulli")
m6
confusionMatrix(m6)
m6_estimates = predict(m6, clean_boost2)
postResample(m6_estimates, as.factor(clean_boost2$Impact))
##Accuracy 0.859, avg = 0.74



##Merging Data
politics_300 <- read_csv("text-stats-politics-300.csv")
politics <- data_10000 %>%
  filter(Section == "Politics")
politics_4 <- politics[401:450,]
write.table(politics_4, file="politics_401_450.csv", sep =",", row.names = F)
politics_300 <- left_join(politics_300, politics_2, by = "URL")
write.table(politics_300, file="politics-300-merged.csv", sep =",", row.names=F)
politics_300 <- politics_300 %>% 
  na.omit()%>% 
  select(-ID, -URL, -text, -`Publish date`, -Authors, -Section, -Tags, -`Sort (Views)` , -Title)
write.table(politics_300, file="politics-no-text-merged.csv", sep =",", row.names=F)
```



##Politics Model Analysis Minji
```{r}
##POLITICS 1300
politics_text <- read_csv("text-data-nlp-politics.csv")
politics_text = politics_text[1:1300,]
politics_huff <- politics[1:1300,]
politics_final <- left_join(politics_huff, politics_text, by = "URL")
added_sent <- read_csv("politics_added_sentiment.csv")
added_sent = added_sent %>%
  select(URL, neg1, neg2, neg3, neg4, neg5, pos1, pos2, pos3, pos4, pos5)
added_sent = added_sent[1:1300,]
politics_final <- left_join(politics_final, added_sent, by = "URL")
politics_total_rated <- read_csv("total_1300_impact_scores.csv")
politics_final <- left_join(politics_total_rated, politics_final, by ="URL")
politics_final = politics_final %>%
  select( -text, -`Publish date`, -Authors, -Section, -Tags, -`Sort (Views)`)
politics_final = politics_final %>%
  mutate(Other_Social_ref = `Social refs` - (`Fb refs`+`Tw refs`))%>%
  mutate(Li_ref = as.factor(ifelse(is.na(`Li refs`), 0, 1))) %>% 
  mutate(Pi_ref = as.factor(ifelse(is.na(`Pi refs`), 0, 1))) %>% 
  mutate(Other_int = `Social interactions` - (`Fb interactions` + `Tw interactions`)) %>%
  mutate(Li_int = as.factor(ifelse(is.na(`Li interactions`), 0 , 1))) %>%
  mutate(Pi_int = as.factor(ifelse(is.na(`Pi interactions`), 0 , 1)))

politics_final = politics_final %>%
  select( -`Li refs`, -`Pi refs`, -`Li interactions`, -`Pi interactions`, -ID, -`Social interactions`, -`Social refs`)

NA_find <-as.data.frame(is.na(politics_final))

##10 missing variables.
##1 row had no social media refs/interaction at all. 
##3 had no faulty URL 
##5 had No NLP and Sentiments 
##3 had No Sentiments
politics_final <- politics_final[-c(290, 303, 398, 399, 678, 680, 1079, 1151, 1162, 1174),]

dulplicated <- as.data.frame(duplicated(politics_final) | duplicated(politics_final, fromLast = TRUE))

politics_final <- politics_final[-c(446, 546, 693, 744, 1177, 1258),]

dulplicated_check2 <- as.data.frame(duplicated(politics_final) | duplicated(politics_final, fromLast = TRUE))

NA_find2 <- as.data.frame(is.na(politics_final))



##Cleaning data 
spaceless <- function(x) {colnames(x) <- gsub(" ", "_", colnames(x));x}
hless <- function(x) {colnames(x) <- gsub("-", "_", colnames(x));x}
politics_final <- spaceless(politics_final)
politics_final <- hless(politics_final)
names(politics_final)
politics_final2 = politics_final %>% 
  mutate(Impact = as.factor(ifelse(impact == 1, "Y", "N" ))) %>% 
  mutate(Engaged_hours=Engaged_minutes/60)%>%
  mutate(Returning_vis_10000=Returning_vis./10000)%>%
  mutate(Search_refs_10000=Search_refs/10000)%>%
  mutate(Internal_refs_10000=Internal_refs/10000)%>%
  mutate(Other_refs_10000=Other_refs/10000)%>%
  mutate(Direct_refs_10000=Direct_refs/10000)%>%
  mutate(Fb_refs_10000=Fb_refs/10000)%>%
  mutate(Tw_refs_10000=Tw_refs/10000)%>%
  mutate(Fb_interactions_10000=Fb_interactions/10000)%>%
  mutate(total_words_10=total_words/10)
  
dulplicated_check3 <- as.data.frame(duplicated(politics_final2) | duplicated(politics_final2, fromLast = TRUE))

NA_find3 <- as.data.frame(is.na(politics_final2))  
  
  
write.table(politics_final2, file="FINAL_DATA_FOR_MODELS.csv", sep = ",", row.names = F )




#politics_300 <- politics_300 %>%
  #mutate(metric = Social_interactions/Views)

##Classification Tree of the whole dataset
tree_p <- tree(as.factor(impact) ~. -URL -Title, data =politics_final)
summary(tree_p)
plot(tree_p)
text(tree_p, pretty=0)

##Training and Testing
set.seed(1)
politics_train <- pf %>%
  sample_frac(0.5)

politics_test <- pf%>%
  setdiff(politics_train)

##Classication tree
set.seed(5)
mp0 <- tree(as.factor(impact) ~ . -URL -Title, data=politics_train)
summary(mp0)
plot(mp0)
text(mp0, pretty = 0)
mp0_estimates = predict(mp0, politics_test, type = "class")
table(mp0_estimates, politics_test$impact)
(329+90)/641 ##65% correct predictions 


##Pruned tree with CV 
set.seed(5)
mp1 <- cv.tree(mp0, FUN = prune.misclass)
plot(mp1$size, mp1$dev, type = "b")
mp2 <- prune.misclass(mp0, best = 5)
plot(mp2)
text(mp2, pretty = 0)
mp2_estimates = predict(mp2, politics_test, type = "class")
table(mp2_estimates, politics_test$impact)
(343+107)/641 ##70.2% correct predictions

##Random Forest model 
set.seed(5)
mp3 <- randomForest(as.factor(impact) ~.-URL -Title,data=politics_train, importance = TRUE, ntree=2000, mtry=5)
varImpPlot(mp3)
mp3_estimates = predict(mp3, newdata = politics_test, n.trees = 2000) 
table(mp3_estimates, politics_test$impact)
(351+106)/641 ##71.3% correct predictions

##Random Forest model with Conditional inference (uses statistical test rather than purity)
set.seed(5)
mp4 <- randomForest(as.factor(impact) ~.-URL -Title , data=politics_train, controls=cforest_unbiased(ntree=2000, mtry=5))
varImpPlot(mp4)
mp4_estimates = predict(mp4, newdata = politics_test, type = "response") 
table(mp4_estimates, politics_test$impact)
(347+107)/641 ## 70.8% correct predictions

pf <- read_csv("FINAL_DATA_FOR_MODELS.csv")
psql <- read_csv("FINAL_DATA_FOR_SQL.csv")


##Boosting with Classification 
mp5<- gbm(impact ~ . -URL -Title, data = politics_train, distribution = "bernoulli", n.trees = 2000, cv.folds = 5, verbose = F)
best.iter = gbm.perf(mp5, method = "cv")

politics_boost <- politics_final %>%
  mutate(Impact = as.factor(ifelse(impact == 1, "Y", "N" ))) %>%
  select(-impact)

set.seed(5)
politics_boost_train <- politics_boost %>% 
  sample_frac(0.5)

politics_boost_test <- politics_boost %>% 
  setdiff(politics_boost_train)
  

mp7 <- gbm(impact ~ . -URL -Title , data = politics_final, distribution = "bernoulli", cv.folds = 5, verbose = F, shrinkage = 0.01, interaction.depth = 1, n.trees = best.iter, n.minobsinnode = 1)
summary(mp7)

tune = expand.grid(interaction.depth = c(1, 2, 3),
                    n.trees = (0:50)*50, 
                    shrinkage = c(.1 ,.01, .001),
                    n.minobsinnode = (1:10))

set.seed(5)
fitControl = trainControl(method="cv", summaryFunction =  twoClassSummary, classProbs = TRUE, number = 5, returnResamp = "all")
mpf6 <- train(Impact ~ Visitors + Views + Engaged_minutes + New_vis.+ Returning_vis.+ Avg._views_new_vis. + Avg._views_ret._vis.+ Avg._minutes_new_vis.+ Avg._minutes_ret._vis. + Desktop_views + Mobile_views + Tablet_views+Search_refs + Internal_refs + Other_refs  +Direct_refs + Fb_refs + Tw_refs + Fb_interactions + Tw_interactions + readability + grade_level + smog_index + total_words + total_sentences + neg1 + neg2 + neg3 + neg4 + neg5 + pos1 + pos2 + pos3 + pos4 + pos5 + Other_Social_ref + Li_ref + Pi_ref + Other_int + Li_int + Pi_int, data=pf, method="gbm", trControl=fitControl, tuneGrid = tune, verbose=FALSE,  metric = "ROC", distribution = "bernoulli")
mp6
varImp(mp6)


confusionMatrix(mp6)
predictions <- predict(object=mp6, pf, type='raw')
mp6_estimates = predict(mp6, pf)
confusionMatrix(mp6_estimates, as.factor(pf$Impact))
confusionMatrix(predictions,  as.factor(pf$Impact))
##Accuracy 82.7% CI (0.8053, 0.8474) Kappa 0.614
postResample(predictions, as.factor(politics_boost$Impact))
postResample(mp6_estimates, as.factor(politics_boost$Impact))


# probabilites 
politics_boost2 = politics_boost %>%
  select(-URL, -Title)

library(pROC)
predictions2 <- predict(object=mp6, pf, type='prob')
head(predictions2)

mod2$xlevels[["y"]] <- union(mod2$xlevels[["y"]], levels(test$y))
mp6$xlevels[["URL"]] <- union(mp6$xlevels[["URL"]], levels(psql2$URL))

outcomeName <- 'Impact'
predictorsNames <- names(pf)[names(pf) != outcomeName]
pf <- read_csv("FINAL_DATA_FOR_MODELS.csv")
psql <- read_csv("FINAL_DATA_FOR_SQL.csv")

psql2 <- psql %>% 
  setdiff(pf) %>%
  mutate(impact = 2)

outcomeName <- 'Impact'
predictorsNames <- names(pf)[names(pf) != outcomeName]

NA_find3 <- as.data.frame(is.na(psql2[,predictorsNames]))  

predictions3 <-predict(mp6, newdata=psql, type="prob")
pred <- predict(object=mpf6, newdata = psql2[,predictorsNames], type='prob')

str(psql2)

#AUC socre
auc = roc(ifelse(pf[,45] == "Y", 1, 0), predictions2[[2]])
print(auc$auc)

gbm.probs <- predict(mp6,pf,type="prob")
head(gbm.probs)
 
mp6.roc <- roc(pf$Impact, gbm.probs[, "Y"], levels = rev(levels(pf$Impact)))

logpred <- read_csv("pred_logistic_regression5.csv")

pf2 <- pf %>% 
  mutate(Impact2 = as.factor(Impact))

log.ROC <-roc(predictor=logpred$N, response=pf2$Impact2, levels=rev(levels(pf2$Impact2)))

gbm.ROC <- roc(predictor=predictions2$Y,
               response=pf2$Impact2,
               levels=rev(levels(pf2$Impact2)))
gbm.ROC$auc

plot(gbm.ROC, main="ROC Comparison")
plot(log.ROC, main = "log roc")
plot(log.ROC, add=TRUE)

plot(gbm.ROC, colorize = TRUE)
plot(log.ROC, add = TRUE, colorize = TRUE)

##0.914
 
plot(varImp(mpf6), nbars = 10)

politics_tree <- pf %>% 
  select(total_words, Views, Tw_interactions,total_sentences, Other_int, Fb_interactions, Visitors, pos3, readability, Mobile_views, smog_index, Tw_refs, Direct_refs, Fb_refs, pos1, neg2, grade_level, pos2, Desktop_views, Avg._views_ret._vis., Impact)


set.seed(5)
politics_tree_train <- politics_tree %>% 
  sample_frac(0.5)

politics_tree_test <- politics_tree %>% 
  setdiff(politics_tree_train)

boost_tree <- tree(as.factor(Impact) ~., politics_tree_train)
summary(boost_tree)
plot(boost_tree)
text(boost_tree, pretty=0)
boost_tree_estimates = predict(boost_tree, politics_tree_test, type = "class")
table(boost_tree_estimates, politics_tree_test$Impact)

(352+89)/(340+116+73+110)

##0.7593

fitboost <- rpart(as.factor(Impact) ~ ., method="class", data=politics_tree_train)
plot(fitboost, uniform =TRUE)
text(fitboost, use.n=TRUE, all=TRUE, cex=.8, pretty=0)
prp(fitboost, type=1, extra=1, under.col = 3, varlen=15)
rpart.plot(fitboost,                    # middle graph
               extra=104, box.palette="GnBu",
               branch.lty=3, shadow.col="gray", nn=TRUE)
fit_tree_estimates = predict(fitboost, politics_tree_test, type = "class")
table(fit_tree_estimates, politics_tree_test$Impact)
(342+107)/(342+143+50+107) ##70%

printcp(fitboost)
summary(fitboost)
fitboost

save(mpf6, file = "GBM_Final.rda")
```

#Turk Analysis
```{r}
Turk <- read_csv("Batch_3145287_batch_results.csv")


Turk_time<-Turk %>%
  filter(WorkTimeInSeconds >= 29)

tidyTurk <- Turk %>% 
  mutate(y = ifelse(Answer.categories == "category 1", 0, 1)) %>%
  group_by(Input.URL) %>%
  summarise(ys = paste(y, collapse = ","))%>%
  separate(ys, into = c("y1", "y2", "y3"))

##Correlations
corTurk <- tidyTurk %>%
  select(y1, y2, y3)

corTurk$y1 <- as.numeric(corTurk$y1)
corTurk$y2 <- as.numeric(corTurk$y2)
corTurk$y3 <- as.numeric(corTurk$y3)
check <- rcorr(as.matrix(corTurk))
listcheck <- as.list(corTurk)
check
check2 <- corr.test(corTurk)
check2

random <- data.frame(replicate(3,sample(0:1,2500,rep=TRUE)))
cor.test(corTurk$y1, corTurk$y2, alternative = "two.sided")
cor.test(corTurk$y1, corTurk$y3, alternative = "two.sided")
cor.test(corTurk$y2, corTurk$y3, alternative = "two.sided")
cor.test(random$X1, random$X2)
cor.test(random$X1, random$X3)
cor.test(random$X2, random$X3)

print(r.test(n=2500, 0.02238351, -0.03225803))
print(r.test(n=2500, 0.0487411, -0.01529797))
print(r.test(n=2500, 0.03599165, 0.009449315))

#Majority rules
Turk2 <- Turk_time %>% 
  mutate(y = ifelse(Answer.categories == "category 1", 0, 1)) %>%
  select(Input.URL, y)

Turk2 <- data.table(Turk2)

Turk2 <- Turk2[,as.numeric(names(which.max(table(y)))),by=Input.URL]

Turk2 <- data.frame(Turk2)
tally(Turk2$V1)

#majority rules-- all 1
Turk3 <- tidyTurk %>%
  mutate(all1 = ifelse(y1 == 1 & y2 == 1 & y3 == 1, 1, 0))

tally(Turk3$all1)

```

SQL DATA 
```{r}
##POLITICS 1300
politics_text2 <- read_csv("text-data-nlp-politics.csv")
politics_text2 = politics_text2[1301:2790,]
politics_huff2 <- politics[1301:2794,]
politics_sql <- left_join(politics_huff2, politics_text2, by = "URL")
added_sent2 <- read_csv("politics_added_sentiment.csv")
added_sent2 = added_sent2 %>%
  select(URL, neg1, neg2, neg3, neg4, neg5, pos1, pos2, pos3, pos4, pos5)
added_sent2 = added_sent2[1301:2790,]
politics_sql <- left_join(politics_sql, added_sent2, by = "URL")
politics_sql = politics_sql %>%
  select( -text, -`Publish date`, -Authors, -Section, -Tags, -`Sort (Views)`)
politics_sql = politics_sql %>%
  mutate(Other_Social_ref = `Social refs` - (`Fb refs`+`Tw refs`))%>%
  mutate(Li_ref = as.factor(ifelse(is.na(`Li refs`), 0, 1))) %>% 
  mutate(Pi_ref = as.factor(ifelse(is.na(`Pi refs`), 0, 1))) %>% 
  mutate(Other_int = `Social interactions` - (`Fb interactions` + `Tw interactions`)) %>%
  mutate(Li_int = as.factor(ifelse(is.na(`Li interactions`), 0 , 1))) %>%
  mutate(Pi_int = as.factor(ifelse(is.na(`Pi interactions`), 0 , 1)))

politics_sql = politics_sql %>%
  select( -`Li refs`, -`Pi refs`, -`Li interactions`, -`Pi interactions`, -ID, -`Social interactions`, -`Social refs`)

NA_find <-as.data.frame(is.na(politics_sql))
##1494 obs

politics_sql = politics_sql %>% 
  na.omit()


dulplicated <- as.data.frame(duplicated(politics_sql) | duplicated(politics_sql, fromLast = TRUE))


##Cleaning data 
spaceless <- function(x) {colnames(x) <- gsub(" ", "_", colnames(x));x}
hless <- function(x) {colnames(x) <- gsub("-", "_", colnames(x));x}
politics_sql <- spaceless(politics_sql)
politics_sql <- hless(politics_sql)
names(politics_sql)
politics_sql = politics_sql %>% 
  mutate(Engaged_hours=Engaged_minutes/60)%>%
  mutate(Returning_vis_10000=Returning_vis./10000)%>%
  mutate(Search_refs_10000=Search_refs/10000)%>%
  mutate(Internal_refs_10000=Internal_refs/10000)%>%
  mutate(Other_refs_10000=Other_refs/10000)%>%
  mutate(Direct_refs_10000=Direct_refs/10000)%>%
  mutate(Fb_refs_10000=Fb_refs/10000)%>%
  mutate(Tw_refs_10000=Tw_refs/10000)%>%
  mutate(Fb_interactions_10000=Fb_interactions/10000)%>%
  mutate(total_words_10=total_words/10)
  
dulplicated_check3 <- as.data.frame(duplicated(politics_sql) | duplicated(politics_sql, fromLast = TRUE))

NA_find3 <- as.data.frame(is.na(politics_sql))

politics_sql = politics_sql %>%
  mutate(impact = NA)%>% 
  mutate(Impact = NA)

politics_sql <- politics_sql[c("URL","impact", "Title","Visitors","Views" ,"Engaged_minutes", "New_vis.", "Returning_vis.", "Avg._views_new_vis.", "Avg._views_ret._vis.", "Avg._minutes_new_vis.", "Avg._minutes_ret._vis.", "Desktop_views",          "Mobile_views", "Tablet_views", "Search_refs", "Internal_refs", "Other_refs", "Direct_refs", "Fb_refs","Tw_refs", "Fb_interactions", "Tw_interactions",        "readability","grade_level", "smog_index","total_words", "total_sentences", "neg1", "neg2", "neg3","neg4", "neg5", "pos1", "pos2", "pos3", "pos4", "pos5", "Other_Social_ref", "Li_ref", "Pi_ref", "Other_int", "Li_int", "Pi_int", "Impact", "Engaged_hours", "Returning_vis_10000", "Search_refs_10000", "Internal_refs_10000", "Other_refs_10000", "Direct_refs_10000", "Fb_refs_10000", "Tw_refs_10000", "Fb_interactions_10000", "total_words_10")]

politics_sql <- bind_rows(politics_final2, politics_sql)

NA_find4 <- as.data.frame(is.na(politics_sql))
  
write.table(politics_sql, file="FINAL_DATA_FOR_SQL.csv", sep = ",", row.names = F )
```

# Erina

```{r}
#join manually rated impact scores
MK <- read_csv("C:/Users/choco/Desktop/SPRING 2018/Capstone/minji_50_impact.csv") %>%
  select(-X1) #import original data
JA <- read_csv("C:/Users/choco/Desktop/SPRING 2018/Capstone/julianna_50_impact.csv")  %>%
  select(-X1)#import original data
ZA <- read_csv("C:/Users/choco/Desktop/SPRING 2018/Capstone/zainab_50_impact.csv")  %>%
  select(-X1)#import original data
EF <- read_csv("C:/Users/choco/Desktop/SPRING 2018/Capstone/erina_50_impact.csv") %>%
  select(-X1) #import original data

MK$`Publish date` = as.character(MK$`Publish date`)
JA$`Publish date` = as.character(JA$`Publish date`)
ZA$`Publish date` = as.character(ZA$`Publish date`)
EF$`Publish date` = as.character(EF$`Publish date`)

rated_200 <- rbind(MK, JA)
rated_200 <- rbind(rated_200,ZA)
rated_200 <- rbind(rated_200,EF)

write.csv(rated_200, file = "C:/Users/choco/Desktop/SPRING 2018/Capstone/rated_200.csv")

MK2 <- read_csv("C:/Users/choco/Desktop/SPRING 2018/Capstone/minji_75_impact.csv")
JA2 <- read_csv("C:/Users/choco/Desktop/SPRING 2018/Capstone/julianna_75_impact.csv")
ZA2 <- read_csv("C:/Users/choco/Desktop/SPRING 2018/Capstone/zainab_75_impact.csv")
EF2 <- read_csv("C:/Users/choco/Desktop/SPRING 2018/Capstone/erina_75_impact.csv")


textual <- read_csv("C:/Users/choco/Desktop/SPRING 2018/Capstone/text-data-politics (3).csv") %>%
  select(c(URL, Text))

MK2 <- left_join(MK2, textual, by="URL")
MK2 <- MK2 %>%
  select(-Text.x) %>%
  rename(Text = Text.y)

MK2 <- MK2[c(2,1,3)]



rated_300 <- rbind(MK2, JA2)
rated_300 <- rbind(rated_300,ZA2)
rated_300 <- rbind(rated_300,EF2)
```


# Erina
#read packages
```{r}
#join manually rated impact scores
MK <- read_csv("C:/Users/choco/Desktop/SPRING 2018/Capstone/minji_50_impact.csv") %>%
  select(-X1) #import original data
JA <- read_csv("C:/Users/choco/Desktop/SPRING 2018/Capstone/julianna_50_impact.csv")  %>%
  select(-X1)#import original data
ZA <- read_csv("C:/Users/choco/Desktop/SPRING 2018/Capstone/zainab_50_impact.csv")  %>%
  select(-X1)#import original data
EF <- read_csv("C:/Users/choco/Desktop/SPRING 2018/Capstone/erina_50_impact.csv") %>%
  select(-X1) #import original data

MK$`Publish date` = as.character(MK$`Publish date`)
JA$`Publish date` = as.character(JA$`Publish date`)
ZA$`Publish date` = as.character(ZA$`Publish date`)
EF$`Publish date` = as.character(EF$`Publish date`)

rated_200 <- rbind(MK, JA)
rated_200 <- rbind(rated_200,ZA)
rated_200 <- rbind(rated_200,EF)

write.csv(rated_200, file = "C:/Users/choco/Desktop/SPRING 2018/Capstone/rated_200.csv")

MK2 <- read_csv("C:/Users/choco/Desktop/SPRING 2018/Capstone/minji_75_impact.csv")
JA2 <- read_csv("C:/Users/choco/Desktop/SPRING 2018/Capstone/julianna_75_impact.csv")
ZA2 <- read_csv("C:/Users/choco/Desktop/SPRING 2018/Capstone/zainab_75_impact.csv")
EF2 <- read_csv("C:/Users/choco/Desktop/SPRING 2018/Capstone/erina_75_impact.csv")


textual <- read_csv("C:/Users/choco/Desktop/SPRING 2018/Capstone/text-data-politics (3).csv") %>%
  select(c(URL, Text))

MK2 <- left_join(MK2, textual, by="URL")
MK2 <- MK2 %>%
  select(-Text.x) %>%
  rename(Text = Text.y)

MK2 <- MK2[c(2,1,3)]
# data_1000_EF<- read_csv("Raw data_10000 articles_Jul-Dec 2017.csv")
# names(data_1000_EF)
# lm1 <- lm(log(`Engaged minutes`)~.-URL-Title-Authors-Tags,data=data_1000_EF)
# summary(lm1)
# anova(lm1)
# 
# plot(lm1)
# summary(data_1000_EF)


library(readr)
library(tidytext)
library(dplyr)
library(tidyr)
library(stringr)
library(Amelia)
library(tidyr)
library(logistf)
library(pscl)
library(ROCR)
library(MKmisc)
library(survey)
library(ResourceSelection)
```


#Sentiment Analysis
```{r}
#probably the correct code - cleaned so may be missing some parts

data_s <- read_csv("C:/Users/choco/Desktop/SPRING 2018/Capstone/text-data-nlp-politics.csv")

data("stop_words") #import stop words

data_s$text<- str_replace_all(data_s$text, "[[:punct:]]", "") #omit special characters
afinn <- get_sentiments("afinn")

words <- data_s %>%
  unnest_tokens(word, text)

words <- words %>%
  anti_join(stop_words)

afinn_neg5 <- get_sentiments("afinn") %>%
    filter(score == -5)
afinn_neg4 <- get_sentiments("afinn") %>%
    filter(score == -4)
afinn_neg3 <- get_sentiments("afinn") %>%
    filter(score == -3)
afinn_neg2 <- get_sentiments("afinn") %>%
    filter(score == -2)
afinn_neg1 <- get_sentiments("afinn") %>%
    filter(score == -1)
afinn_0 <- get_sentiments("afinn") %>%
    filter(score == 0)
afinn_pos1 <- get_sentiments("afinn") %>%
    filter(score == 1)
afinn_pos2 <- get_sentiments("afinn") %>%
    filter(score == 2)
afinn_pos3 <- get_sentiments("afinn") %>%
    filter(score == 3)
afinn_pos4 <- get_sentiments("afinn") %>%
    filter(score == 4)
afinn_pos5 <- get_sentiments("afinn") %>%
    filter(score == 5)

filter_sentiments <- function(x, ...) {
  get_sentiments("afinn") %>%
    filter(score == x)
}

output <- lapply(-5:5, filter_sentiments) %>%
  bind_rows()


words <- text %>%
#  group_by(URL) %>%
  unnest_tokens(word, article)

words <- words %>%
  anti_join(stop_words)

neg5 <- words %>%
  group_by(URL) %>%
  inner_join(afinn_neg5) %>%
	inner_join(output) %>%
	count(word, sort=TRUE)
neg5$score <- "-5"

neg4 <- words %>%
  group_by(URL) %>%
	inner_join(afinn_neg4) %>%
	count(word, sort=TRUE)
neg4$score <- "-4"

neg3 <- words %>%
  group_by(URL) %>%
	inner_join(afinn_neg3) %>%
	count(word, sort=TRUE)
neg3$score <- "-3"

neg2 <- words %>%
  group_by(URL) %>%
	inner_join(afinn_neg2) %>%
	count(word, sort=TRUE)
neg2$score <- "-2"

neg1 <- words %>%
  group_by(URL) %>%
	inner_join(afinn_neg1) %>%
	count(word, sort=TRUE)
neg1$score <- "-1"

neg1$score <- "-1"

pos1 <- words %>%
  group_by(URL) %>%
	inner_join(afinn_pos1) %>%
	count(word, sort=TRUE)
pos1$score <- "1"

pos2 <- words %>%
  group_by(URL) %>%
	inner_join(afinn_pos2) %>%
	count(word, sort=TRUE)
pos2$score <- "2"

pos3 <- words %>%
  group_by(URL) %>%
	inner_join(afinn_pos3) %>%
	count(word, sort=TRUE)
pos3$score <- "3"

pos4 <- words %>%
  group_by(URL) %>%
	inner_join(afinn_pos4) %>%
	count(word, sort=TRUE)
pos4$score <- "4"

pos5 <- words %>%
  group_by(URL) %>%
	inner_join(afinn_pos5) %>%
	count(word, sort=TRUE)
pos5$score <- "5"

neg5_2 <- neg5 %>%
  group_by(URL) %>%
  summarise(n_sum=sum(n))
neg5_2$score <- "neg5"

neg4_2 <- neg4 %>%
  group_by(URL) %>%
  summarise(n_sum=sum(n))
neg4_2$score <- "neg4"


neg3_2 <- neg3 %>%
  group_by(URL) %>%
  summarise(n_sum=sum(n))
neg3_2$score <- "neg3"

neg2_2 <- neg2 %>%
  group_by(URL) %>%
  summarise(n_sum=sum(n))
neg2_2$score <- "neg2"

neg1_2 <- neg1 %>%
  group_by(URL) %>%
  summarise(n_sum=sum(n))
neg1_2$score <- "neg1"

pos1_2 <- pos1 %>%
  group_by(URL) %>%
  summarise(n_sum=sum(n))
pos1_2$score <- "pos1"

pos2_2 <- pos2 %>%
  group_by(URL) %>%
  summarise(n_sum=sum(n))
pos2_2$score <- "pos2"

pos3_2 <- pos3 %>%
  group_by(URL) %>%
  summarise(n_sum=sum(n))
pos3_2$score <- "pos3"

pos4_2 <- pos4 %>%
  group_by(URL) %>%
  summarise(n_sum=sum(n))
pos4_2$score <- "pos4"

pos5_2 <- pos5 %>%
  group_by(URL) %>%
  summarise(n_sum=sum(n))
pos5_2$score <- "pos5"

# rbindfunc <- function(sentiments,x){
#   sentiments <- rbind(sentiments,x)
# return(sentiments)
# }

#lapply(rbindfunc,rbindfunc(sentiment,c(neg3_2,neg2_2,neg1_2,pos1_2,pos2_2,pos3_2,pos4_2,pos5_2)))

sentiment <- rbind(neg5_2, neg4_2)
sentiment <- rbind(sentiment, neg3_2)
sentiment <- rbind(sentiment, neg2_2)
sentiment <- rbind(sentiment, neg1_2)
sentiment <- rbind(sentiment, pos1_2)
sentiment <- rbind(sentiment, pos2_2)
sentiment <- rbind(sentiment, pos3_2)
sentiment <- rbind(sentiment, pos4_2)
sentiment <- rbind(sentiment, pos5_2)

sentiment <- sentiment %>%
  spread(key=score, value=n_sum)

sentiment[is.na(sentiment)] <- 0

sentiment <- sentiment %>%
  mutate(total_n = neg5+neg4+neg3+neg2+neg1+pos1+pos2+pos3+pos4+pos5) %>%
  mutate(neg5=neg5/total_n) %>%
  mutate(neg4=neg4/total_n) %>%
  mutate(neg3=neg3/total_n) %>%
  mutate(neg2=neg2/total_n) %>%
  mutate(neg1=neg1/total_n) %>%
  mutate(pos1=pos1/total_n)%>%
  mutate(pos2=pos2/total_n)%>%
  mutate(pos3=pos3/total_n)%>%
  mutate(pos4=pos4/total_n)%>%
  mutate(pos5=pos5/total_n)

data_added_sentiment <- full_join(data_EF,sentiment,by="URL")

data_added_sentiment <- data_added_sentiment %>%
  mutate(average_sent = neg5*-5+neg4*-4+neg3*-3+neg2*-2+neg1*-1+pos1*1+pos2*2+pos3*3+pos4*4+pos5*5)

data_added_sentiment <- data_added_sentiment %>%
  select(-total_n)



write.csv(data_added_sentiment, file = "C:/Users/choco/Desktop/SPRING 2018/Capstone/data_added_sentiment.csv")

neg3_2 <- neg3 %>%
  group_by(URL) %>%
  summarise(n_sum=sum(n))
neg3_2$score <- "neg3"

neg2_2 <- neg2 %>%
  group_by(URL) %>%
  summarise(n_sum=sum(n))
neg2_2$score <- "neg2"

neg1_2 <- neg1 %>%
  group_by(URL) %>%
  summarise(n_sum=sum(n))
neg1_2$score <- "neg1"

pos1_2 <- pos1 %>%
  group_by(URL) %>%
  summarise(n_sum=sum(n))
pos1_2$score <- "pos1"

pos2_2 <- pos2 %>%
  group_by(URL) %>%
  summarise(n_sum=sum(n))
pos2_2$score <- "pos2"

pos3_2 <- pos3 %>%
  group_by(URL) %>%
  summarise(n_sum=sum(n))
pos3_2$score <- "pos3"

pos4_2 <- pos4 %>%
  group_by(URL) %>%
  summarise(n_sum=sum(n))
pos4_2$score <- "pos4"

pos5_2 <- pos5 %>%
  group_by(URL) %>%
  summarise(n_sum=sum(n))
pos5_2$score <- "pos5"

sentiment <- rbind(neg5_2, neg4_2)
sentiment <- rbind(sentiment, neg3_2)
sentiment <- rbind(sentiment, neg2_2)
sentiment <- rbind(sentiment, neg1_2)
sentiment <- rbind(sentiment, pos1_2)
sentiment <- rbind(sentiment, pos2_2)
sentiment <- rbind(sentiment, pos3_2)
sentiment <- rbind(sentiment, pos4_2)
sentiment <- rbind(sentiment, pos5_2)

sentiment <- sentiment %>%
  spread(key=score, value=n_sum)

sentiment[is.na(sentiment)] <- 0

sentiment <- sentiment %>%
  mutate(total_n = neg5+neg4+neg3+neg2+neg1+pos1+pos2+pos3+pos4+pos5) %>%
  mutate(neg5=neg5/total_n) %>%
  mutate(neg4=neg4/total_n) %>%
  mutate(neg3=neg3/total_n) %>%
  mutate(neg2=neg2/total_n) %>%
  mutate(neg1=neg1/total_n) %>%
  mutate(pos1=pos1/total_n)%>%
  mutate(pos2=pos2/total_n)%>%
  mutate(pos3=pos3/total_n)%>%
  mutate(pos4=pos4/total_n)%>%
  mutate(pos5=pos5/total_n)

data_added_sentiment2 <- full_join(data_p,sentiment,by="URL")

#write.csv(data_added_sentiment2, file = "C:/Users/choco/Desktop/SPRING 2018/Capstone/politics_added_sentiment.csv")
```


#Logistic Regression
```{r}
ldata <- read_csv("C:/Users/choco/Desktop/SPRING 2018/Capstone/politics-data-for-model (2).csv")

ldata<-ldata %>%
  select(-URL, -Title)

ldata[is.na(ldata)]<-0

#split into train and test
train <- ldata[1:600,]
test <- ldata[601:889,]

m1 <- glm(impact~.,family=binomial(link = "logit"), data=train)
step(m1,direction="both")

step(m1,
     scope = list(upper=m1),
             direction="both",
             test="Chisq",
             data=Data)

#m2 <- glm(impact~Avg._minutes_new_vis.+smog_index+pos3+pos4+neg3+pos1+neg2+neg4+pos2+neg5+neg1+total_words+Fb_interactions,family=binomial(link = "logit"), data=train)

m2<-glm(formula = impact ~ Views + Engaged_minutes + New_vis. + Avg._views_new_vis. + 
    Avg._minutes_new_vis. + Desktop_views + Internal_refs + Fb_interactions + 
    smog_index + total_words + neg1 + neg2 + neg3 + neg4 + neg5 + 
    pos1 + pos2 + pos3 + pos4, family = binomial(link = "logit"), 
    data = train)



#m5 <- glm(impact~ neg1 +neg3 +pos1 +pos2 +smog_index  + neg2 + total_words,family=binomial(link = "logit"), data=train)

summary(m5)
anova(m5)


pR2(m5)

xyplot(log(fitted.values(m5)/(1-fitted.values(m5)))~impact, data=ldata, type=c("l"),ylab="log odds")
xyplot(fitted.values(m5)/(1-fitted.values(m5))~impact, data=ldata, ylab="odds")



fitted.results <- predict(m1,newdata=subset(train,select=c(2,3,4,5,6,7,8)),type='response')
fitted.results <- ifelse(fitted.results > 0.5,1,0)
misClasificError <- mean(fitted.results != ldata2$impact)
print(paste('Accuracy',1-misClasificError))

p <- predict(m5, newdata=subset(test,select=c(2,3,4,5,6,7,8)), type="response")
pr <- prediction(p, ldata$impact)
prf <- performance(pr, measure = "tpr", x.measure = "fpr")
plot(prf)

auc <- performance(pr, measure = "auc")
auc <- auc@y.values[[1]]
auc

# Compute AUC for predicting Class with the model
prob <- predict(m5, newdata=test, type="response")
pred <- prediction(prob, test$impact)
perf <- performance(pred, measure = "tpr", x.measure = "fpr")
plot(perf)
auc <- performance(pred, measure = "auc")
auc <- auc@y.values[[1]]
auc

test$impact<-as.factor(test$impact)
ldata$impact <- as.factor(ldata$impact)

ctrl <- trainControl(method = "repeatedcv", number = 10, savePredictions = TRUE)

mod_fit <- train(impact~ neg1 +neg3 +pos1 +pos2 + Social_interactions +smog_index  + neg2 + total_words,  data=ldata, method="glm", family="binomial",
                 trControl = ctrl, tuneLength = 5)


pred = predict(mod_fit, newdata=test)

cfm1<-confusionMatrix(data=pred, test$impact)
```

Social impact:change in way of thinking/attitude or brings someone to take action or change the way they act; leaves an impression or makes the reader think even if it doesn’t change his or her views
Quality Journalism:accurate, clear, multiple sources, relevance, change in way of thinking/attitude/action (includes above)
_Social impact can be a smaller part of quality journalism but not vice versa?_
https://www.huffingtonpost.com/2012/04/16/huffington-post-pulitzer-prize-2012_n_1429169.html


# Julianna 

```{r}
library(dplyr)
library(mosaic)
library(Hmisc)
library(car)
library(leaps)
library(tidyr)
library(data.table)
library(psych)

data_10000 %>%
  arrange(`Engaged minutes`) %>%
  select(Title)

ggplot(data = data_10000, aes(log(`Social interactions`))) + geom_histogram()

ggplot(data = data_10000, aes(log(`Views`))) + geom_histogram()

ggplot(data = data_10000, aes(`Views`)) + geom_histogram()

test <- data_10000 %>%
  mutate(`huff_metric` = `Social interactions`/ `Views`, log_huff_metric = log(huff_metric)) %>%
  arrange(desc(huff_metric))

fav_stats(test$log_huff_metric)

ggplot(data = test, aes(log(`huff_metric`))) + geom_histogram()

ggplot(data = test, aes(x = log(`Social interactions`), y = log(`Engaged minutes`))) + geom_point() + 
  geom_smooth()

test <- test %>%
  mutate(log_social_interactions = log(`Social interactions`), log_engaged_minutes = log(`Engaged minutes`), log_views = log(`Views`))

cor(test$log_social_interactions, test$log_engaged_minutes, use = "complete.obs")

qqnorm(test$log_huff_metric)
qqline(test$log_huff_metric, col = "red")

qqnorm(test$log_social_interactions)
qqline(test$log_social_interactions, col = "red")

qqnorm(test$Views)
qqline(test$Views, col = "red")

qqnorm(test$log_views)
qqline(test$log_views, col = "red")

##MODELS--------------------------------------------------

#Finding predictors from backward and stepwise regression
fullmodel <- lm(`huff_metric`~`Views`+`Engaged minutes`+`Returning vis.`+`New vis.`+`Social refs`+`Social interactions`+`Avg. minutes new vis.`+`Avg. minutes ret. vis.`+`Visitors`+`Avg. views new vis.`+`Avg. views ret. vis.`, data = test)

#Using log variables
fullmodel <- lm(log_huff_metric~`Views`+log_engaged_minutes+`Returning vis.`+`New vis.`+`Social refs`+log_social_interactions+`Avg. minutes new vis.`+`Avg. minutes ret. vis.`+`Visitors`+`Avg. views new vis.`+`Avg. views ret. vis.`, data = test)


# backward
fullMSE <- (summary(fullmodel)$sigma)^2
step(fullmodel, data = test, scale = fullMSE, direction = "backward")

test<-na.omit(test)
#stepwise
nullmodel <- lm(`huff_metric` ~ 1, data = test)
step(nullmodel, scope = list(upper = fullmodel),
scale = fullMSE, direction = "both")

#Stepwise gave me this model:
mod_huff <- lm(formula = huff_metric ~ `Social interactions` + `Avg. minutes ret. vis.` + 
    `Returning vis.` + `Engaged minutes` + `New vis.` + `Social refs` + 
    Views + `Avg. views new vis.`, data = test)

summary(mod_huff)

plot(mod_huff)

  #cor matrix for the model
selected_data_mod_step <- test %>%
  select(`Social interactions`, `Avg. minutes ret. vis.`, 
    `Returning vis.`, `Engaged minutes`, `New vis.`, `Social refs`, 
    Views, `Avg. views new vis.`)

  #Nothing abnormally high except (engaged min and returning visitors), (new vis and views), (Social refs and views)
res2 <- rcorr(as.matrix(selected_data_mod_step))
res2

  #checking VIF
vif(mod_huff)
#There are big issues of multicollinearity in this model

##How about best subset approach?

allsubset<-regsubsets(`huff_metric`~`Views`+`Engaged minutes`+`Returning vis.`+`New vis.`+`Social refs`+`Social interactions`+`Avg. minutes new vis.`+`Avg. minutes ret. vis.`+`Visitors`+`Avg. views new vis.`+`Avg. views ret. vis.`, data = test)
options(digits=3)

summary(allsubset)$adjr2
plot(allsubset,scale="adjr2")

summary(allsubset)$cp
plot(allsubset,scale="Cp")

#Using log variables
allsubset_log<-regsubsets(log_huff_metric~`Views`+`Engaged minutes`+`Returning vis.`+`New vis.`+`Social refs`+`Social interactions`+`Avg. minutes new vis.`+`Avg. minutes ret. vis.`+`Visitors`+`Avg. views new vis.`+`Avg. views ret. vis.`, data = test)
options(digits=3)

summary(allsubset_log)$adjr2
plot(allsubset_log,scale="adjr2")

summary(allsubset_log)$cp
plot(allsubset_log,scale="Cp")

#Gives us THIS model:
mod_all <- lm(`huff_metric`~`Views`+`Engaged minutes`+`Returning vis.`+`New vis.`+`Social interactions`+`Social refs`+`Avg. minutes ret. vis.`, data = test)

summary(mod_all)

#Log
mod_all_log <- lm(log_huff_metric~`Views`+`Returning vis.`+`New vis.`+`Social refs`+`Social interactions`+`Avg. minutes ret. vis.`+ `Avg. minutes new vis.`+Visitors, data = test)

summary(mod_all_log)

car::vif(mod_all_log)

plot(mod_all_log)

  #Checking for multicollinearity again
selected_data_mod_best <- test %>%
  select(`Views`,`Engaged minutes`,`Returning vis.`,`New vis.`,`Social refs`,`Social interactions`,`Avg. minutes ret. vis.`)

res2 <- rcorr(as.matrix(selected_data_mod_best))
res2

car::vif(mod_all)

plot(mod_all)
  #Way better with multicollinearity!

#checking section
mod_all_sec1 <- lm(`huff_metric`~`Views`+`Engaged minutes`+`Returning vis.`+`New vis.`+`Social refs`+`Social interactions`+`Avg. minutes ret. vis.`+ `Avg. views new vis.`+Section, data = test)

summary(mod_all_sec1)

test_comb_section <- test %>%
  mutate(black_voices = ifelse(Section == "Black Voices", "yes", "no"))
#what happens when I add that to the model?
mod_all_sec <- lm(`huff_metric`~`Views`+`Engaged minutes`+`Returning vis.`+`New vis.`+`Social refs`+`Social interactions`+`Avg. minutes ret. vis.`+ `Avg. views new vis.`+black_voices, data = test_comb_section)

#This should be something we consider. Do sections fit into theoretical definition of social impact?

##how about engaged minutes per viewer?
test <- test %>%
  mutate(engaged_min_per_view = `Engaged minutes`/Views, engaged_min_per_ret_vis = `Engaged minutes`/`Returning vis.`)%>%
  arrange(desc(engaged_min_per_ret_vis))

mosaic::favstats(test$engaged_min_per_view)

ggplot(test, aes(engaged_min_per_view)) + geom_histogram()

mosaic::favstats(test$engaged_min_per_ret_vis)

ggplot(test, aes(log(engaged_min_per_ret_vis))) + geom_histogram()

#Amazon Mechanical Turks Analysis

Turk <- read_csv("Batch_3145287_batch_results.csv")
######################################

Turk_time<-Turk %>%
  filter(WorkTimeInSeconds >= 29)

tidyTurk <- Turk %>% 
  mutate(y = ifelse(Answer.categories == "category 1", 0, 1)) %>%
  group_by(Input.URL) %>%
  summarise(ys = paste(y, collapse = ","))%>%
  separate(ys, into = c("y1", "y2", "y3"))

corTurk <- tidyTurk %>%
  select(y1, y2, y3)

check <- rcorr(as.matrix(corTurk))
check

#Majority rules
Turk2 <- Turk_time %>% 
  mutate(y = ifelse(Answer.categories == "category 1", 0, 1)) %>%
  select(Input.URL, y)

Turk2 <- data.table(Turk2)

Turk2 <- Turk2[,as.numeric(names(which.max(table(y)))),by=Input.URL]

Turk2 <- data.frame(Turk2)
tally(Turk2$V1)

#majority rules-- all 1
Turk3 <- tidyTurk %>%
  mutate(all1 = ifelse(y1 == 1 & y2 == 1 & y3 == 1, 1, 0))

tally(Turk3$all1)

#Corr.test?
tidyTurk$y1 <- as.numeric(tidyTurk$y1)
tidyTurk$y2 <- as.numeric(tidyTurk$y2)

corr.test(tidyTurk$y1, tidyTurk$y2)

#permuting

```


# Zainab

```{r}
require(mosaic)
favstats(data_10000$Views)

c <- ggplot(data_10000, aes(Views))
c+geom_histogram()

fav_stats(data_10000$`Engaged minutes`)
d <- ggplot(data_10000, aes(`Engaged minutes`))
d+geom_histogram()

ggplot(data_10000, aes_string(x = "`Social refs`", y = "`Engaged minutes`")) +
  theme_bw() +
  geom_jitter()

ggplot(data_10000, aes_string(x = "`Returning vis.`", y = "`Engaged minutes`")) +
  theme_bw() +
  geom_jitter()

ggplot(data_10000, aes_string(x = "Visitors", y = "`Engaged minutes`")) +
  theme_bw() +
  geom_jitter()

data_10000 = data_10000 %>%
  mutate(logEngMins = log(`Engaged minutes`))

data_10000 = data_10000 %>%
  mutate(logRetVisitors = log(`Returning vis.`))

ggplot(data_10000, aes_string(x = "logRetVisitors", y = "logEngMins")) +
  theme_bw() +
  geom_jitter()

c <- ggplot(data_10000, aes(logRetVisitors))
c+geom_histogram()

f <- ggplot(data_10000, aes(logEngMins))
f+geom_histogram()

ggplot(data_10000, aes_string(x = "`Social refs`", y = "Visitors")) +
  theme_bw() +
  geom_jitter()

ggplot(data_10000, aes_string(x = "`Social refs`", y = "`New vis.`")) +
  theme_bw() +
  geom_jitter()


data_10000 %>%
  select(c(`Returning vis.`,`Social refs`, `Engaged minutes`, `Avg. views new vis.`, Views, Visitors, `New vis.`))%>%
  cor()
```


```{bash}
python3 parser.py data/politics.csv
```



