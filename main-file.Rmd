---
title: "main-file"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Remains the same for everyone

```{r}
library(readr)
# change this according to your
data_10000 <- read_csv("Raw data_10000 articles_Jul-Dec 2017.csv")
```

# Key terms

Social impact:
change in way of thinking/attitude or brings someone to take action or change the way they act; leaves an impression or makes the reader think even if it doesnâ€™t change his or her views

Quality Journalism:
accurate, clear, multiple sources, relevance, change in way of thinking/attitude/action (includes above)

_Social impact can be a smaller part of quality journalism but not vice versa?_

https://www.huffingtonpost.com/2012/04/16/huffington-post-pulitzer-prize-2012_n_1429169.html

# Sections for everyone

# Minji

```{r}
##removing na's and creating the existing metric
Sint_PV <- data_10000%>%
  mutate(metric = `Social interactions`/Views)%>%
  arrange(desc(metric))%>%
  na.omit(`Engaged minutes`)%>%
  na.omit(`Social interactions`)

##creating vectors 
engaged_min <- Sint_PV$`Engaged minutes`
metric <-Sint_PV$metric
soc_int <- Sint_PV$`Social interactions`
pv <- Sint_PV$`Views`
rv <- Sint_PV$`Returning vis.`

##looking at the correlations
cor(engaged_min, soc_int)
cor(engaged_min, metric)
cor(engaged_min, pv)
cor(engaged_min, rv)
cor(rv, metric)

##Pareto Distribution
library(ParetoPosStable)
pareto.fit(pv, estim.method = "MLE")

ggplot(pv, aes(log(V))) + geom_histogram(aes(y=..density..), bins = 100 ) + stat_function(fun = dnorm, args = list(11.68749, 1.013802), color = "red")

p <- ggplot(pv, aes(V)) + geom_histogram(aes(y=..density..), bins = 100) 
p+ stat_function(fun = dpareto, args = list(7795, 0.4751), color = "red")

###################################################################################################


merged_200 <- read_csv("merged_200.csv")
minji_50 <- merged_200[101:150,]
write.table(minji_50, file="minji_50.csv",sep=",",row.names=F)
minji_50_impact <- read_csv("minji_50_impact.csv")

```


# Erina

```{r}
#join manually rated impact scores
MK <- read_csv("C:/Users/choco/Desktop/SPRING 2018/Capstone/minji_50_impact.csv") %>%
  select(-X1) #import original data
JA <- read_csv("C:/Users/choco/Desktop/SPRING 2018/Capstone/julianna_50_impact.csv")  %>%
  select(-X1)#import original data
ZA <- read_csv("C:/Users/choco/Desktop/SPRING 2018/Capstone/zainab_50_impact.csv")  %>%
  select(-X1)#import original data
EF <- read_csv("C:/Users/choco/Desktop/SPRING 2018/Capstone/erina_50_impact.csv") %>%
  select(-X1) #import original data

MK$`Publish date` = as.character(MK$`Publish date`)
JA$`Publish date` = as.character(JA$`Publish date`)
ZA$`Publish date` = as.character(ZA$`Publish date`)
EF$`Publish date` = as.character(EF$`Publish date`)

rated_200 <- rbind(MK, JA)
rated_200 <- rbind(rated_200,ZA)
rated_200 <- rbind(rated_200,EF)

write.csv(rated_200, file = "C:/Users/choco/Desktop/SPRING 2018/Capstone/rated_200.csv")
```


```{r}
# data_1000_EF<- read_csv("Raw data_10000 articles_Jul-Dec 2017.csv")
# names(data_1000_EF)
# lm1 <- lm(log(`Engaged minutes`)~.-URL-Title-Authors-Tags,data=data_1000_EF)
# summary(lm1)
# anova(lm1)
# 
# plot(lm1)
# summary(data_1000_EF)

library(readr)
library(tidytext)
library(dplyr)
library(tidyr)
library(stringr)

data_EF <- read_csv("Raw data_10000 articles_Jul-Dec 2017.csv") #import original data

data("stop_words") #import stop words
text <- read_csv("text-data.csv") %>%
  select(URL, article) #import textual data

text$article<- str_replace_all(text$article, "[[:punct:]]", "") #omit special characters
afinn <- get_sentiments("afinn")

afinn_neg5 <- get_sentiments("afinn") %>%
    filter(score == -5)
afinn_neg4 <- get_sentiments("afinn") %>%
    filter(score == -4)
afinn_neg3 <- get_sentiments("afinn") %>%
    filter(score == -3)
afinn_neg2 <- get_sentiments("afinn") %>%
    filter(score == -2)
afinn_neg1 <- get_sentiments("afinn") %>%
    filter(score == -1)
afinn_0 <- get_sentiments("afinn") %>%
    filter(score == 0)
afinn_pos1 <- get_sentiments("afinn") %>%
    filter(score == 1)
afinn_pos2 <- get_sentiments("afinn") %>%
    filter(score == 2)
afinn_pos3 <- get_sentiments("afinn") %>%
    filter(score == 3)
afinn_pos4 <- get_sentiments("afinn") %>%
    filter(score == 4)
afinn_pos5 <- get_sentiments("afinn") %>%
    filter(score == 5)


words <- text %>%
#  group_by(URL) %>%
  unnest_tokens(word, article)

words <- words %>%
  anti_join(stop_words)

neg5 <- words %>%
  group_by(URL) %>%
	inner_join(afinn_neg5) %>%
	count(word, sort=TRUE)
neg5$score <- "-5"

neg4 <- words %>%
  group_by(URL) %>%
	inner_join(afinn_neg4) %>%
	count(word, sort=TRUE)
neg4$score <- "-4"

neg3 <- words %>%
  group_by(URL) %>%
	inner_join(afinn_neg3) %>%
	count(word, sort=TRUE)
neg3$score <- "-3"

neg2 <- words %>%
  group_by(URL) %>%
	inner_join(afinn_neg2) %>%
	count(word, sort=TRUE)
neg2$score <- "-2"

neg1 <- words %>%
  group_by(URL) %>%
	inner_join(afinn_neg1) %>%
	count(word, sort=TRUE)
neg1$score <- "-1"

pos1 <- words %>%
  group_by(URL) %>%
	inner_join(afinn_pos1) %>%
	count(word, sort=TRUE)
pos1$score <- "1"

pos2 <- words %>%
  group_by(URL) %>%
	inner_join(afinn_pos2) %>%
	count(word, sort=TRUE)
pos2$score <- "2"

pos3 <- words %>%
  group_by(URL) %>%
	inner_join(afinn_pos3) %>%
	count(word, sort=TRUE)
pos3$score <- "3"

pos4 <- words %>%
  group_by(URL) %>%
	inner_join(afinn_pos4) %>%
	count(word, sort=TRUE)
pos4$score <- "4"

pos5 <- words %>%
  group_by(URL) %>%
	inner_join(afinn_pos5) %>%
	count(word, sort=TRUE)
pos5$score <- "5"

neg5_2 <- neg5 %>%
  group_by(URL) %>%
  summarise(n_sum=sum(n))
neg5_2$score <- "neg5"

neg4_2 <- neg4 %>%
  group_by(URL) %>%
  summarise(n_sum=sum(n))
neg4_2$score <- "neg4"

neg3_2 <- neg3 %>%
  group_by(URL) %>%
  summarise(n_sum=sum(n))
neg3_2$score <- "neg3"

neg2_2 <- neg2 %>%
  group_by(URL) %>%
  summarise(n_sum=sum(n))
neg2_2$score <- "neg2"

neg1_2 <- neg1 %>%
  group_by(URL) %>%
  summarise(n_sum=sum(n))
neg1_2$score <- "neg1"

pos1_2 <- pos1 %>%
  group_by(URL) %>%
  summarise(n_sum=sum(n))
pos1_2$score <- "pos1"

pos2_2 <- pos2 %>%
  group_by(URL) %>%
  summarise(n_sum=sum(n))
pos2_2$score <- "pos2"

pos3_2 <- pos3 %>%
  group_by(URL) %>%
  summarise(n_sum=sum(n))
pos3_2$score <- "pos3"

pos4_2 <- pos4 %>%
  group_by(URL) %>%
  summarise(n_sum=sum(n))
pos4_2$score <- "pos4"

pos5_2 <- pos5 %>%
  group_by(URL) %>%
  summarise(n_sum=sum(n))
pos5_2$score <- "pos5"

# rbindfunc <- function(sentiments,x){
#   sentiments <- rbind(sentiments,x)
# return(sentiments)
# }

#lapply(rbindfunc,rbindfunc(sentiment,c(neg3_2,neg2_2,neg1_2,pos1_2,pos2_2,pos3_2,pos4_2,pos5_2)))

sentiment <- rbind(neg5_2, neg4_2)
sentiment <- rbind(sentiment, neg3_2)
sentiment <- rbind(sentiment, neg2_2)
sentiment <- rbind(sentiment, neg1_2)
sentiment <- rbind(sentiment, pos1_2)
sentiment <- rbind(sentiment, pos2_2)
sentiment <- rbind(sentiment, pos3_2)
sentiment <- rbind(sentiment, pos4_2)
sentiment <- rbind(sentiment, pos5_2)

sentiment <- sentiment %>%
  spread(key=score, value=n_sum)

sentiment[is.na(sentiment)] <- 0

sentiment <- sentiment %>%
  mutate(total_n = neg5+neg4+neg3+neg2+neg1+pos1+pos2+pos3+pos4+pos5) %>%
  mutate(neg5=neg5/total_n) %>%
  mutate(neg4=neg4/total_n) %>%
  mutate(neg3=neg3/total_n) %>%
  mutate(neg2=neg2/total_n) %>%
  mutate(neg1=neg1/total_n) %>%
  mutate(pos1=pos1/total_n)%>%
  mutate(pos2=pos2/total_n)%>%
  mutate(pos3=pos3/total_n)%>%
  mutate(pos4=pos4/total_n)%>%
  mutate(pos5=pos5/total_n)

data_added_sentiment <- full_join(data_EF,sentiment,by="URL")
```

```{r}
#####Erina continued



words %>%
	group_by(URL) %>%
	inner_join() %>%
	count(word, sort=TRUE)

words %>%
	group_by(URL) %>%
	inner_join(afinn_neg5) %>%
	count(word, sort=TRUE)

words <- words %>%
  group_by(URL) %>%
  mutate(proportion = n / sum(n))

words <- words%>%
  count(word, sort = TRUE) %>%
  #select(-n) %>% 
  spread(URL, proportion) %>% 
  gather(URL, proportion, 2:3)



#words %>%
 # group_by(article) %>%
  #count(word, sort = TRUE) 

#write.csv(text, file = "C:/Users/choco/Desktop/SPRING 2018/Capstone/text_cleanedinR.csv") #create new csv file
```


# Julianna 

```{r}
data_10000 %>%
  arrange(`Engaged minutes`) %>%
  select(Title)

ggplot(data = data_10000, aes(log(`Social interactions`))) + geom_histogram()

ggplot(data = data_10000, aes(log(`Views`))) + geom_histogram()

ggplot(data = data_10000, aes(`Views`)) + geom_histogram()

test <- data_10000 %>%
  mutate(`huff_metric` = `Social interactions`/ `Views`, log_huff_metric = log(huff_metric)) %>%
  arrange(desc(huff_metric))

fav_stats(test$log_huff_metric)

ggplot(data = test, aes(log(`huff_metric`))) + geom_histogram()

ggplot(data = test, aes(x = log(`Social interactions`), y = log(`Engaged minutes`))) + geom_point() + 
  geom_smooth()

test <- test %>%
  mutate(log_social_interactions = log(`Social interactions`), log_engaged_minutes = log(`Engaged minutes`), log_views = log(`Views`))

cor(test$log_social_interactions, test$log_engaged_minutes, use = "complete.obs")

qqnorm(test$log_huff_metric)
qqline(test$log_huff_metric, col = "red")

qqnorm(test$log_social_interactions)
qqline(test$log_social_interactions, col = "red")

qqnorm(test$Views)
qqline(test$Views, col = "red")

qqnorm(test$log_views)
qqline(test$log_views, col = "red")
```


# Zainab

```{r}
require(mosaic)
favstats(data_10000$Views)

c <- ggplot(data_10000, aes(Views))
c+geom_histogram()

fav_stats(data_10000$`Engaged minutes`)
d <- ggplot(data_10000, aes(`Engaged minutes`))
d+geom_histogram()

ggplot(data_10000, aes_string(x = "`Social refs`", y = "`Engaged minutes`")) +
  theme_bw() +
  geom_jitter()

ggplot(data_10000, aes_string(x = "`Returning vis.`", y = "`Engaged minutes`")) +
  theme_bw() +
  geom_jitter()

ggplot(data_10000, aes_string(x = "Visitors", y = "`Engaged minutes`")) +
  theme_bw() +
  geom_jitter()

data_10000 = data_10000 %>%
  mutate(logEngMins = log(`Engaged minutes`))

data_10000 = data_10000 %>%
  mutate(logRetVisitors = log(`Returning vis.`))

ggplot(data_10000, aes_string(x = "logRetVisitors", y = "logEngMins")) +
  theme_bw() +
  geom_jitter()

c <- ggplot(data_10000, aes(logRetVisitors))
c+geom_histogram()

f <- ggplot(data_10000, aes(logEngMins))
f+geom_histogram()

ggplot(data_10000, aes_string(x = "`Social refs`", y = "Visitors")) +
  theme_bw() +
  geom_jitter()

ggplot(data_10000, aes_string(x = "`Social refs`", y = "`New vis.`")) +
  theme_bw() +
  geom_jitter()


data_10000 %>%
  select(c(`Returning vis.`,`Social refs`, `Engaged minutes`, `Avg. views new vis.`, Views, Visitors, `New vis.`))%>%
  cor()
```


